{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad.tensor import Tensor\n",
    "from tinygrad.nn import Linear\n",
    "from extra.utils import print_tree\n",
    "from tinygrad.nn.optim import Adam\n",
    "from tinygrad.jit import TinyJit\n",
    "from tinygrad.helpers import dtypes\n",
    "from tinygrad.shape.shapetracker import ShapeTracker\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./training.txt\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [\"\",\"<unk>\"]+list(set(data))\n",
    "char2idx = {c:i for i,c in enumerate(chars)}\n",
    "nchars = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(*text: list[str]):\n",
    "    maxlen = max(len(t) for t in text)\n",
    "    X = np.zeros((len(text), maxlen, nchars))\n",
    "    for i,line in enumerate(text):\n",
    "        for j,char in enumerate(line):\n",
    "            if char in char2idx:X[i, j, char2idx[char]] = 1\n",
    "            else: X[i, j, char2idx['<unk>']] = 1\n",
    "    return Tensor(X,dtype=dtypes.float) \n",
    "\n",
    "def decode_text(X:Tensor):\n",
    "    X = X.numpy()\n",
    "    return [\"\".join([chars[char.argmax()] for char in line])\n",
    "            for line in X]\n",
    "\n",
    "assert decode_text(encode_text(\"hello\",\"world€€€\")) == ['hello','world<unk><unk><unk>']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN():\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.hh = Linear(hidden_size, hidden_size)\n",
    "        self.xh = Linear(input_size, hidden_size)\n",
    "        self.hy = Linear(hidden_size, output_size)\n",
    "        self.h = Tensor.zeros(1,hidden_size)\n",
    "        self.layers = [self.hh, self.xh, self.hy]\n",
    "        self.params = [param for layer in self.layers for param in (layer.weight, layer.bias)]\n",
    "\n",
    "\n",
    "def forward (rnn:RNN,x:Tensor,h:Tensor):\n",
    "    h = (rnn.hh(h.layernorm()) + rnn.xh(x)).relu().realize()\n",
    "    return rnn.hy(h).softmax().realize(), h\n",
    "\n",
    "def call(rnn,X:Tensor):\n",
    "    assert X.shape [2] == nchars\n",
    "    res = []\n",
    "    \n",
    "    for s in X:\n",
    "        seq = []\n",
    "        rnn.h = Tensor.zeros(rnn.h.shape)\n",
    "        jitted_forward = TinyJit(forward)\n",
    "\n",
    "        for x in s:\n",
    "            x_ = Tensor(x.lazydata.buffers[0].toCPU()).reshape(1,-1)\n",
    "            p,rnn.h = jitted_forward(rnn,x_,rnn.h)\n",
    "            seq.append(p)\n",
    "        res.append(Tensor.cat(*seq,dim=0))\n",
    "    return Tensor.cat(*res).reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "rnn = RNN(nchars, 256, nchars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 ━┳ RESHAPE (2, 5, 67)\n",
      "  1  ┗━┳ ADD  \n",
      "  2    ┣━┳ ADD \n",
      "  3    ┃ ┣━┳ ADD \n",
      "  4    ┃ ┃ ┣━┳ ADD \n",
      "  5    ┃ ┃ ┃ ┣━┳ ADD \n",
      "  6    ┃ ┃ ┃ ┃ ┣━┳ PAD ((0, 9), (0, 0))\n",
      "  7    ┃ ┃ ┃ ┃ ┃ ┗━━ realized float (1, 67)  \n",
      "  8    ┃ ┃ ┃ ┃ ┗━┳ PAD ((1, 8), (0, 0)) \n",
      "  9    ┃ ┃ ┃ ┃   ┗━━ realized float (1, 67)  \n",
      " 10    ┃ ┃ ┃ ┗━┳ PAD ((2, 7), (0, 0)) \n",
      " 11    ┃ ┃ ┃   ┗━━ realized float (1, 67)  \n",
      " 12    ┃ ┃ ┗━┳ PAD ((3, 6), (0, 0)) \n",
      " 13    ┃ ┃   ┗━━ realized float (1, 67)  \n",
      " 14    ┃ ┗━┳ PAD ((4, 5), (0, 0)) \n",
      " 15    ┃   ┗━━ realized float (1, 67)  \n",
      " 16    ┗━┳ ADD  \n",
      " 17      ┣━┳ ADD \n",
      " 18      ┃ ┣━┳ ADD \n",
      " 19      ┃ ┃ ┣━┳ ADD \n",
      " 20      ┃ ┃ ┃ ┣━┳ PAD ((5, 4), (0, 0))\n",
      " 21      ┃ ┃ ┃ ┃ ┗━━ realized float (1, 67)  \n",
      " 22      ┃ ┃ ┃ ┗━┳ PAD ((6, 3), (0, 0)) \n",
      " 23      ┃ ┃ ┃   ┗━━ realized float (1, 67)  \n",
      " 24      ┃ ┃ ┗━┳ PAD ((7, 2), (0, 0)) \n",
      " 25      ┃ ┃   ┗━━ realized float (1, 67)  \n",
      " 26      ┃ ┗━┳ PAD ((8, 1), (0, 0)) \n",
      " 27      ┃   ┗━━ realized float (1, 67)  \n",
      " 28      ┗━┳ PAD ((9, 0), (0, 0)) \n",
      " 29        ┗━━ realized float (1, 67)  \n"
     ]
    }
   ],
   "source": [
    "pred = call(rnn,encode_text(\"hello\",\"world\"))\n",
    "print_tree(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "develop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
