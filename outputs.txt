Modules length: 107
Loading weights file (237MB). This might take a whileâ€¦
running inference
warning, (1, 3, 416, 416) isn't float32
Outputs from 0 [<Conv2d Layer with in_channels 3, out_channels 32, weights with shape (32, 3, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x100ff38e0>, <tinygrad.nn.LeakyReLU object at 0x112d3b3a0>] convolutional
[-0.10670715 -0.04778621 -0.04778621 -0.04778621 -0.04778621 -0.04778621
 -0.04778621 -0.04782076 -0.04711483 -0.04557068 -0.04553969 -0.04531703
 -0.04569411 -0.0519707  -0.05304933 -0.06407356 -0.05586381 -0.05202897
 -0.04029653 -0.04010906 -0.37402305 -0.44142792 -0.5467881  -0.5687515
 -0.39210877 -0.5259364  -0.5237042  -0.6144965  -0.6185566  -0.5635907
 -0.6151237  -0.62887007 -0.5771641  -0.36056802 -0.47290215 -0.3788823
 -0.5503363  -0.55132735 -0.30771935 -0.4812263  -0.4627355  -0.41539946
 -0.37021297 -0.0351681  -0.3207353  -0.14046621 -0.5318018  -0.39657432
 -0.63780373 -0.38365048 -0.46708852 -0.13094357 -0.44299576 -0.49172765
 -0.34749982 -0.8240175  -0.4764107   0.04420424 -0.10793634 -0.33401376
 -0.59169906 -0.40767008 -0.5820319  -0.8305578  -0.5337009  -0.6971683
 -0.34086287 -0.66090786 -0.71214783 -0.53919286 -0.4613745  -0.51260716
 -0.48697272 -0.38441825 -0.29871964 -0.3585546  -0.23357525 -0.26619703
 -0.614099   -0.535958   -0.516345   -0.5255826  -0.47443888 -0.5216012
 -0.6543147  -0.43124363 -0.5336926  -0.47533914 -0.45009533 -0.5230434
 -0.74115926 -0.58284473 -0.2403957  -0.39151907 -0.6987522  -0.5920858
 -0.6702038  -0.41507664 -0.3006358  -0.5281886  -0.36131135 -0.8685749
 -0.85344696 -0.7896753  -0.8064006  -0.8071557  -0.73369604 -0.66042966
 -0.75314677 -0.6791819  -0.66982764 -0.7645273  -0.6725287  -0.52536243
 -0.51429003 -0.51063246 -0.47273588 -0.40440845 -0.6472039  -0.76785535
 -0.3335963  -0.6474522  -0.52763975 -0.20368111 -0.5087129  -0.2693603
 -0.42467555 -0.22076789 -0.05441368 -0.17900054 -0.5232218  -0.3151209
 -0.31950256 -0.4182965  -0.5098836  -0.4100333  -0.6992893  -0.16605492
 -0.6356662  -0.8064801  -0.57936543 -0.29086724 -0.46226683 -0.5604035
 -0.51161873 -0.42964432 -0.26571628 -0.39797464 -0.43978125 -0.44441912
 -0.39221987  0.04310608 -0.31592748 -0.64115137 -0.49275753 -0.516509
 -0.32592916 -0.3376977  -0.2411855  -0.19471963 -0.6819835  -0.8275715
 -0.67651266 -0.6441761  -0.66838115 -0.33002725 -0.45571968 -0.78529674
 -0.3089157  -0.39011374 -0.38807127 -0.30299264 -0.79237485 -0.63484496
 -0.73829836 -0.83332366 -0.81985503 -0.773976   -0.67069924 -0.75842285
 -0.6947951  -0.21161227 -0.7900681  -0.6663293  -0.49792057 -0.51071656
 -0.6974213  -0.6989317  -0.18396036 -0.27279112 -0.18139939 -0.15317678
 -0.42881152 -0.21111988 -0.24104486 -0.21263881 -0.22596279 -0.19491105
 -0.12219031 -0.14461826 -0.10412874 -0.3415552  -0.17375381 -0.18535367
 -0.30334803 -0.19833802 -0.17080346 -0.15209818 -0.21038125 -0.31981775
 -0.17983592 -0.24413686 -0.18774138 -0.23125386 -0.21601366 -0.2062817
 -0.2063421  -0.2546744  -0.24889056 -0.24572544 -0.23559204 -0.23940046
 -0.19620211 -0.1650232  -0.16481231 -0.2433794  -0.24115396 -0.22891204
 -0.2417932  -0.06821437 -0.5877506  -0.46182775 -0.05215659 -0.16767712
 -0.22510636 -0.14893265 -0.26953068 -0.33186355 -0.5149434  -0.39983043
 -0.63046336 -0.8403388  -0.8300112  -0.8134953  -0.880829   -0.87082195
 -0.7086588  -0.2559211  -0.50225306 -0.6700811  -0.73547786 -0.76160204
 -0.8645493  -0.94099057 -0.81393635 -0.6296775  -0.49225315 -0.831438
 -0.43330166 -0.8421534  -0.57123226 -0.18517263 -0.34437424 -0.2692237
 -0.23030208 -0.21153088 -0.21553253 -0.20932125 -0.18662582 -0.28031108
 -0.25841042 -0.2345654  -0.24247275 -0.17946883 -0.24335681 -0.1770237
 -0.21519223 -0.2449563  -0.19936399 -0.36400813 -0.10300548 -0.20950548
 -0.18001783 -0.21904874 -0.2979624  -0.2329705  -0.13672407 -0.19779181
 -0.2603024  -0.19893849 -0.3093907  -0.22493222 -0.061759   -0.26323512
 -0.10576876  0.33332157 -0.12382567 -0.2692348  -0.27655974 -0.06974895
 -0.25853416 -0.16656378 -0.3917176  -0.32178685 -0.0977031  -0.14675064
 -0.19538131 -0.67884743 -0.3853701  -0.19116683 -0.17969976 -0.27561072
 -0.9792339  -0.71193975 -0.7201767  -0.53221256 -0.545453   -0.7607438
 -0.7967349  -0.8590004  -0.7029166  -0.6093728  -0.47211075 -0.54003704
 -0.8845652  -0.74412143 -0.58221984 -0.41456977 -0.5351586  -0.34506392
 -0.26392302 -0.42698675 -0.09059749 -0.3157619  -0.37532806 -0.09695504
 -0.35366064 -0.63050646 -0.65614575 -0.5235459  -0.2939644  -0.04187706
 -0.32595864 -0.71313924 -0.65519917 -0.5047209  -0.2098882  -0.08012591
 -0.46728626 -0.00253863 -0.02053819 -0.06594422 -0.00452361 -0.14326079
 -0.05346856 -0.04578755 -0.06213701 -0.05891464 -0.19426249 -0.3156084
 -0.20677495 -0.03708737  0.03035545 -0.09691735  0.21689892 -0.04271076
 -0.19398883  0.81804705  1.116404    0.41680384 -0.00169587 -0.06783295
 -0.03679433  0.9094796   0.6386652   1.0689068  -0.02793407 -0.09859421
 -0.04595535 -0.24499221 -0.15938988  1.2677503   1.0066757   0.30985117
  0.73381567  0.6696663  -0.5444564  -0.12321156  0.21667671  0.7958002
  0.16488361  1.9869142  -0.11069989 -0.22863553  0.26401758  0.09361076
 -0.7670538  -0.6686186  -0.35187536 -0.15036047  0.43196535 -0.04893639
  0.3207121  -0.00710526 -0.18630622 -0.39126226 -0.28535685 -0.5599581
 -1.0509752  -0.9956648  -0.7071468  -0.66608566 -0.6661091  -0.87557167
 -0.28929138 -0.00481954]
Outputs from 1 [<Conv2d Layer with in_channels 32, out_channels 64, weights with shape (64, 32, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d582b0>, <tinygrad.nn.LeakyReLU object at 0x112d582e0>] convolutional
[ 0.10603629 -0.02068292 -0.02068292 -0.02002209 -0.0214121  -0.02153642
 -0.02759086 -0.02861219 -0.0186489  -0.12923907 -0.02309495  0.84307134
 -0.11055966 -0.11581635  0.11905476  0.99715686 -0.04697977  1.0887315
  0.3911009  -0.23323122  0.9438634  -0.03451527  3.3314996   0.8466775
  0.6521675   0.47295555 -0.08368745 -0.19541277  1.9989303  -0.17652076
  0.6404046   1.7442197  -0.09730278 -0.17216562  0.71535623  1.0900335
  0.43777785 -0.12682271 -0.20431302  0.77103394 -0.0577437  -0.07187307
  1.2230163   0.16232756 -0.05262286  1.7527045  -0.24980192  1.5997057
  0.35710603 -0.13939789 -0.3837584   1.9171815   0.7075122  -0.11457469
 -0.09383767  0.09083486 -0.10298337  1.196476   -0.12358886  2.2851822
 -0.26840672  1.9831822   2.0770278   0.654306   -0.23542087  1.8062065
  0.7261872   1.8908153   2.2188182  -0.00373733  2.091528   -0.28038236
  0.73504674 -0.12375002 -0.09096225  2.6595354  -0.00634976  0.8653964
 -0.2568062   0.3354948  -0.14262335  0.29952     1.267569   -0.23667888
 -0.15164284 -0.02401073 -0.12661205 -0.21029507  0.8104769  -0.06727918
  1.7688618   1.3398712  -0.13235264  2.4342191  -0.09539509 -0.10070027
  2.987772   -0.04280502  0.43806574 -0.18553594 -0.06753904 -0.13569672
  1.4445957  -0.09150725 -0.04086567 -0.05106011 -0.05321558  0.20260283
 -0.0991471   0.19844829 -0.07740647  0.18941951 -0.0525247  -0.0101229
  0.18892531 -0.10419613 -0.16883318  0.80199176 -0.11596774 -0.03439707
 -0.18058176  0.16083708  1.2609177   0.70293415 -0.04832739  0.4413701
  0.11963729  1.5573686  -0.29264805 -0.18668878  2.0995378   0.42378464
 -0.05302344 -0.02986038 -0.06900606  0.14153971  0.59804565 -0.01108132
 -0.05126981  0.26923856 -0.09241349 -0.03313879  0.78094524 -0.03005285
 -0.02938829 -0.09225862 -0.20303558  0.7053956  -0.04036388  1.4580344
 -0.28610894  0.6835008  -0.17093937 -0.34513408  3.9737391  -0.3039565
  3.8885279   0.55711824 -0.20479372  1.4798983  -0.17254184 -0.3079482
  3.4714475  -0.03331767  0.8555112  -0.12436378 -0.04601596  2.317625
 -0.28032744  1.7983072   2.039852   -0.42347485  3.2510993   0.4214235
  1.3844169  -0.09891086 -0.0685671  -0.02429865  0.14059399 -0.03260389
 -0.0467336   0.25585517 -0.12098347  2.5565813  -0.11358362 -0.04048397
  0.5977535  -0.16949826  1.0965735  -0.39614534  4.388222   -0.16191535
 -0.08069453  1.985131    0.6880283  -0.07029044  0.5237003  -0.22493327
  3.6744974  -0.15540637 -0.00716077 -0.06688546 -0.19515353  0.09327412
  1.7331778  -0.11109922  0.38129544  1.5167482 ]
Outputs from 2 [<Conv2d Layer with in_channels 64, out_channels 32, weights with shape (32, 64, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d64880>, <tinygrad.nn.LeakyReLU object at 0x112d64910>] convolutional
[-0.16903126 -0.11770945 -0.11770945 -0.11878707 -0.12296301 -0.107319
 -0.10760234 -0.10038967 -0.10202702 -0.08869942  0.52480155 -0.2560466
 -0.29627255 -0.19792359 -0.14154875 -0.2620006  -0.31649622 -0.20411627
 -0.18417822 -0.27478024 -0.20493357 -0.13102888 -0.22655188 -0.30756038
 -0.23533897 -0.24047907 -0.16120751 -0.04193159 -0.2796186  -0.10447061
 -0.10886007 -0.12635146 -0.24923943 -0.0320232  -0.2391318  -0.22229312
 -0.27214354 -0.18501209 -0.02214535 -0.02309702 -0.24945267 -0.14500184
 -0.21233363 -0.33369943 -0.34769246 -0.3565882  -0.22503379 -0.2139695
 -0.3942834  -0.22180796 -0.15772256 -0.21375167 -0.3439996  -0.39636776
 -0.2769121  -0.22170305 -0.2965574  -0.36590025 -0.3233502  -0.25578552
 -0.36598313 -0.13085489 -0.29776844 -0.17925018 -0.25622538 -0.07319838
 -0.14949477 -0.14509712 -0.16214977 -0.00747202 -0.3042898  -0.22475202
 -0.2575937  -0.3396083  -0.3348217  -0.26157528 -0.27420324 -0.34620988
 -0.3295904  -0.2118182  -0.16269289 -0.33020124 -0.3179545  -0.4065455
 -0.29239812 -0.2655903  -0.1841384  -0.09125841 -0.24005829 -0.27813873
 -0.37015194 -0.30103728 -0.33330107 -0.459903   -0.4127048  -0.24543934
 -0.28884134 -0.3294319  -0.30582985 -0.2705218  -0.10859062 -0.19202194
 -0.16501527 -0.28044054 -0.21452199 -0.2736881  -0.24331112 -0.28552967
 -0.26870406 -0.2488619  -0.24076746 -0.22114964 -0.32426706 -0.28666982
 -0.29834923 -0.15317068 -0.3513547  -0.2585559  -0.2733774  -0.34182578
 -0.14200677 -0.19460063 -0.31781575 -0.43378854 -0.20268753 -0.16170618
 -0.1570116  -0.41331458 -0.25174627 -0.22111614 -0.38063788 -0.2477556
 -0.29195786 -0.21051028 -0.15015078 -0.2270931  -0.23619497 -0.24992354
 -0.23895161 -0.26797268 -0.25195175 -0.20553307 -0.18761273 -0.2503138
 -0.23166685 -0.2032963  -0.24389859 -0.2572743  -0.29580587 -0.13731818
 -0.1527727  -0.13140479 -0.2861044  -0.00419811 -0.3253922  -0.34685084
 -0.08445638 -0.27193177 -0.10234054 -0.151129   -0.31426442 -0.2556996
 -0.24065743 -0.36710927 -0.20968461 -0.16765352 -0.26091298 -0.1753744
 -0.3102958  -0.07062937 -0.34225222 -0.11206247 -0.30007434 -0.32595453
 -0.18736741 -0.16781001 -0.22897664 -0.24369183 -0.15464632 -0.31364435
 -0.23934273 -0.12833305 -0.24674033 -0.10973878 -0.27461392 -0.14369969
 -0.25268504 -0.1749361  -0.14192466 -0.07399442 -0.3809203  -0.2198139
 -0.09563877 -0.1494891  -0.27670428 -0.24677327 -0.05832477 -0.28178483
  0.0827726  -0.20120838 -0.17387244 -0.17171861 -0.12361436 -0.01310107
  0.6028729  -0.34392285 -0.2640334  -0.24223137]
Outputs from 3 [<Conv2d Layer with in_channels 32, out_channels 64, weights with shape (64, 32, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d64dc0>, <tinygrad.nn.LeakyReLU object at 0x112d64e50>] convolutional
[-0.13801278 -0.17821734 -0.11206152 -0.11881643 -0.11046457 -0.11569031
 -0.10897615 -0.05556352 -0.12783213 -0.16243377 -0.10819223 -0.17530242
 -0.11162841  0.0911423  -0.23727079 -0.07050671 -0.23353092 -0.38620025
  0.8335624   0.32004488 -0.19523226 -0.3306937  -0.36876345 -0.46434757
 -0.30797577 -0.45454723 -0.07585013  1.8154467  -0.7610945   0.69669557
 -0.32772207 -0.06999723 -0.04809721  0.22194296 -0.21929105 -0.24808688
 -0.2445219   0.4954911  -0.12875436 -0.3038304  -0.16299789 -0.07434473
 -0.43248716 -0.16246833 -0.06136531 -0.1312688  -0.12989531 -0.13443159
 -0.44555065  1.6672984   1.3680305  -0.31622967 -0.28281125 -0.2080642
 -0.12453969  0.4846214  -0.14680645 -0.27775708 -0.1479236   1.054949
  0.82624984 -0.52285194 -0.3616601  -0.10991984 -0.1820847  -0.31042668
 -0.09306512 -0.37853608 -0.69553035  1.2366363  -0.6191648   1.7779719
 -0.21175765 -0.17692314  0.8341247  -0.59105617  1.0637586  -0.15592475
  0.44878006 -0.4316631   1.8057839  -0.32537493 -0.44886968  2.625638
 -0.06512777 -0.40524402 -0.23285365 -0.04966104 -0.23963676 -0.02647273
 -0.7628018   0.12161595 -0.29496917  0.39051735 -0.0127669  -0.10121386
 -0.31725317 -0.16309395 -0.08569636  0.21543431  0.8736168  -0.22166362
 -0.19210741 -0.18266703  1.934265   -0.1318761  -0.09820893 -0.17260577
  0.22174662 -0.13778089 -0.02506598 -0.13056354 -0.13416465 -0.04291289
 -0.41368786  1.6377269  -0.2922232  -0.2750826   0.55947256 -0.4126347
  0.8875979  -0.29520693 -0.01296232 -0.60916656  0.36590964 -0.28957883
  0.17437577 -0.44216082  4.144038    1.5313258  -0.6784075  -0.1132093
 -0.18598984 -0.0773836   0.338278   -0.2606289  -0.24993658 -0.21470118
  0.41233963  0.652812   -0.08267458 -0.05774558 -0.1604086  -0.17904602
 -0.10945644 -0.0685656   1.5573258  -0.386065   -0.04526124 -0.3582048
 -0.1081413  -0.09232727 -0.40074155  4.252859   -0.4651011  -0.04553701
 -0.4145681  -0.29417878 -0.02307744 -0.10252964 -0.20305303 -0.0764465
 -0.20272012 -0.374953   -0.226408    0.8730618  -0.19112118 -0.4631853
 -0.04171475 -0.07734249 -0.76575327  4.0675535  -0.20825706 -0.3945616
 -0.40221697 -0.02973425  0.46266282 -0.20202637 -0.22078796  0.13790774
 -0.13306521  0.00733012 -0.07640251 -0.3403967  -0.29573855  1.1648489
 -0.37253872 -0.21332507 -0.17720045  2.345776   -0.6263619  -0.04314616
 -0.14238472 -0.23520616 -0.30811262 -0.43153712  2.4162965  -0.31836396
 -0.0611585  -0.17815755 -0.22937846 -0.17121187  0.9530735  -0.2756636
  0.10922903 -0.3911546   2.8435183  -0.47894278]
Outputs from 4 [<tinygrad.nn.EmptyLayer object at 0x112d6d310>] shortcut
[-0.03197649 -0.19890025 -0.13274445 -0.13883851 -0.13187666 -0.13722673
 -0.13656701 -0.08417571 -0.14648102 -0.29167283 -0.13128717  0.66776896
 -0.22218807 -0.02467405 -0.11821602  0.92665017 -0.2805107   0.7025313
  1.2246633   0.08681366  0.7486311  -0.36520895  2.9627361   0.3823299
  0.34419173  0.01840833 -0.15953758  1.620034    1.2378359   0.5201748
  0.3126825   1.6742225  -0.14539999  0.04977734  0.4960652   0.84194666
  0.19325595  0.36866838 -0.3330674   0.46720356 -0.22074158 -0.1462178
  0.79052913 -0.00014077 -0.11398817  1.6214356  -0.37969723  1.4652741
 -0.08844462  1.5279006   0.9842721   1.6009518   0.42470095 -0.3226389
 -0.21837735  0.57545626 -0.24978982  0.91871893 -0.27151245  3.3401313
  0.5578431   1.4603302   1.7153677   0.54438615 -0.41750556  1.4957798
  0.6331221   1.5122792   1.5232878   1.232899    1.4723631   1.4975895
  0.5232891  -0.30067316  0.74316245  2.0684793   1.0574088   0.70947164
  0.19197387 -0.09616831  1.6631606  -0.02585495  0.81869924  2.3889592
 -0.21677062 -0.42925474 -0.35946572 -0.2599561   0.5708401  -0.09375191
  1.0060599   1.461487   -0.4273218   2.8247366  -0.10816199 -0.20191413
  2.6705189  -0.20589897  0.35236937  0.02989838  0.8060778  -0.35736036
  1.2524883  -0.27417427  1.8933994  -0.1829362  -0.15142451  0.02999707
  0.12259952  0.0606674  -0.10247245  0.05885597 -0.18668935 -0.05303579
 -0.22476254  1.5335307  -0.46105635  0.5269092   0.4435048  -0.44703177
  0.70701617 -0.13436985  1.2479553   0.09376758  0.31758225  0.15179127
  0.29401305  1.1152078   3.8513901   1.344637    1.4211304   0.31057534
 -0.23901328 -0.10724398  0.26927194 -0.1190892   0.34810907 -0.2257825
  0.36106983  0.9220506  -0.17508808 -0.09088437  0.6205366  -0.20909888
 -0.13884473 -0.16082422  1.3542902   0.31933057 -0.08562513  1.0998296
 -0.39425024  0.5911735  -0.5716809   3.907725    3.5086381  -0.3494935
  3.4739597   0.26293945 -0.22787116  1.3773687  -0.37559485 -0.3843947
  3.2687273  -0.40827066  0.6291032   0.748698   -0.23713714  1.8544397
 -0.3220422   1.7209647   1.2740986   3.6440787   3.0428424   0.02686191
  0.98219997 -0.1286451   0.39409572 -0.22632502 -0.08019397  0.10530385
 -0.17979881  0.2631853  -0.19738598  2.2161846  -0.40932217  1.124365
  0.22521481 -0.38282335  0.91937304  1.9496307   3.7618604  -0.2050615
 -0.22307925  1.7499249   0.37991565 -0.50182754  2.9399967  -0.54329723
  3.613339   -0.33356392 -0.23653923 -0.23809732  0.75791997 -0.1823895
  1.8424067  -0.50225383  3.2248137   1.0378054 ]
Outputs from 5 [<Conv2d Layer with in_channels 64, out_channels 128, weights with shape (128, 64, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d6d370>, <tinygrad.nn.LeakyReLU object at 0x112d6d400>] convolutional
[10.94981    3.8863072  4.420808   4.7020636  3.5950336  8.506109
  5.10279    6.732098   5.1722393  7.456803   5.1578364  5.886061
  7.0734468  9.145632   3.5884576  4.037183   4.7359586  6.6153264
  4.745984   8.9188595  8.52709   13.69471    6.182083  11.3846035
  6.314544   8.947248   7.1792855  7.5114627  9.224056   6.0208344
  6.658586   7.0223308  4.655842   6.3020797  5.972694  10.086582
 12.908281   6.048494   3.477409   9.200813   8.260464   4.8108487
  8.244389   7.5985456  9.154894   5.762758   7.9348645  5.220769
  6.906652   6.650003   7.923018   9.431217   7.8955846  5.7244825
  6.843516   7.329453   6.5962996  6.7081304  5.738257   6.794395
  9.309217   6.594192   9.514153   8.799696   9.471327   7.1288676
  4.7524905  7.310496   6.570769   4.348367   5.1363378  5.9988484
  4.2996683  4.449446   2.85709    8.586142   5.315646   4.0463114
  5.2779694  7.825911   5.3246202  6.279908   8.572748   3.276462
  6.2237897  5.674574   3.0969462  7.319691   3.9943714  3.2200155
  5.3276625  4.552981   3.9775672  3.5383806  6.3123903  3.8398814
  4.9585257  2.1886592  6.510138   4.972475   4.439181   5.5818367
  9.604794  11.734003 ]
Outputs from 6 [<Conv2d Layer with in_channels 128, out_channels 64, weights with shape (64, 128, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d6d8b0>, <tinygrad.nn.LeakyReLU object at 0x112d6d940>] convolutional
[ 1.0118448   0.30063415 -0.02082391 -0.02893912 -0.04938732 -0.02710854
  0.11120009 -0.12437224 -0.09261846 -0.08834144 -0.0740185  -0.10925925
 -0.0602986  -0.10724542 -0.00616652 -0.10503061 -0.04336567 -0.0606629
  0.00361276 -0.18368934 -0.03991093 -0.00521287 -0.11322488 -0.03615069
 -0.09208844 -0.04289758 -0.07649761 -0.12210331 -0.05935292 -0.17610537
 -0.0767152  -0.1066943  -0.0823814  -0.06072931 -0.0642788   0.67372227
  0.0661     -0.06508186 -0.05986737  0.14845401 -0.09662869 -0.09119423
 -0.05692121 -0.03242241 -0.04294194 -0.10968535 -0.06775124 -0.01444649
 -0.08261551 -0.09869088 -0.10186287  0.18763608 -0.06250748 -0.0512032
 -0.09116977 -0.10881706 -0.09785341 -0.21336977 -0.02763763 -0.12699795
 -0.07546432 -0.09507352 -0.05316859 -0.06802595 -0.04241919 -0.04701504
 -0.00894467 -0.0884138  -0.08314755 -0.13223684 -0.04746725 -0.08227085
 -0.16401291 -0.05294846 -0.13221578 -0.11105438 -0.07962327 -0.12389517
 -0.12504165 -0.0920256  -0.0882339  -0.07776641 -0.06301729 -0.09936695
 -0.07863603 -0.03322421 -0.11611342 -0.07090502 -0.02728312 -0.09113079
 -0.11986994 -0.10253992 -0.01115628 -0.08712347 -0.09486943 -0.0259282
 -0.16737281 -0.04788626 -0.16078341 -0.09288649  0.05312651 -0.1461534
 -0.04100467 -0.05900447]
Outputs from 7 [<Conv2d Layer with in_channels 64, out_channels 128, weights with shape (128, 64, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d6ddf0>, <tinygrad.nn.LeakyReLU object at 0x112d6de80>] convolutional
[-0.04259754 -0.04259409 -0.04259417 -0.0425944  -0.04259508 -0.04259715
 -0.04259839 -0.0425984  -0.04259835 -0.04259833 -0.04259867 -0.04259797
 -0.04259859 -0.04259856 -0.04259815 -0.04259728 -0.04259793 -0.04259764
 -0.04259787 -0.04259845 -0.04259972 -0.0425992  -0.0425995  -0.04259852
 -0.04259851 -0.04259939 -0.04259946 -0.04259976 -0.04259959 -0.04259919
 -0.04259877 -0.0425979  -0.04259873 -0.0425988  -0.04259897 -0.04259882
 -0.0425991  -0.04259842 -0.04259899 -0.04259854 -0.04259817 -0.04259822
 -0.04259805 -0.04259904 -0.04259881 -0.04259887 -0.04259892 -0.04259777
 -0.04259755 -0.04259774 -0.04259823 -0.04259861 -0.04259854 -0.04259809
 -0.04259806 -0.04259812 -0.04259786 -0.04259795 -0.04259908 -0.04259888
 -0.04259988 -0.04259994 -0.04259967 -0.04260027 -0.04260013 -0.04259916
 -0.04259783 -0.04259762 -0.04259787 -0.0425979  -0.04259824 -0.04259803
 -0.04259783 -0.0425984  -0.04259854 -0.04259882 -0.04259893 -0.04259941
 -0.04259925 -0.04259843 -0.04259925 -0.04259928 -0.04259886 -0.04260042
 -0.04259975 -0.04259928 -0.0425976  -0.04259735 -0.0425977  -0.04259695
 -0.04259735 -0.04259729 -0.04259726 -0.04259722 -0.04259765 -0.04259737
 -0.042597   -0.0425975  -0.04259923 -0.04259889 -0.04259897 -0.04259995
 -0.04259989 -0.04259973]
Outputs from 8 [<tinygrad.nn.EmptyLayer object at 0x112d71340>] shortcut
[10.907212   3.843713   4.378214   4.659469   3.5524385  8.463512
  5.0601916  6.6895     5.129641   7.4142046  5.1152377  5.8434634
  7.030848   9.103033   3.5458593  3.9945855  4.693361   6.5727286
  4.7033863  8.876261   8.48449   13.652111   6.1394835 11.342005
  6.2719455  8.904649   7.136686   7.468863   9.181457   5.9782352
  6.6159873  6.979733   4.613243   6.259481   5.9300947 10.043983
 12.865683   6.0058956  3.43481    9.158215   8.217866   4.7682505
  8.201791   7.5559464  9.112295   5.720159   7.892266   5.178171
  6.864054   6.607405   7.8804197  9.388618   7.852986   5.6818843
  6.8009176  7.2868547  6.553702   6.6655326  5.6956577  6.7517962
  9.266618   6.551592   9.471553   8.757095   9.428727   7.0862684
  4.7098927  7.267898   6.528171   4.3057694  5.0937395  5.95625
  4.2570705  4.406848   2.8144915  8.543543   5.2730474  4.003712
  5.23537    7.783313   5.282021   6.237309   8.530149   3.2338617
  6.18119    5.6319747  3.0543487  7.277094   3.9517736  3.1774185
  5.285065   4.5103836  3.93497    3.4957833  6.2697926  3.7972841
  4.915929   2.1460617  6.467539   4.9298763  4.3965816  5.5392365
  9.562194  11.691403 ]
Outputs from 9 [<Conv2d Layer with in_channels 128, out_channels 64, weights with shape (64, 128, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d713a0>, <tinygrad.nn.LeakyReLU object at 0x112d71430>] convolutional
[ 5.31925     0.75354385  1.1020868   0.9608984  -0.03693078 -0.10696249
 -0.01921483 -0.15157638  1.6849856   0.9797461  -0.11254859  1.3884742
 -0.12184381 -0.15018037  0.760793   -0.1540886  -0.08179855  0.20171571
  0.16212404 -0.08598816  0.03517324  0.55559015 -0.17373727 -0.05888334
 -0.06190271 -0.00841297 -0.08021764 -0.14403284 -0.01224571  0.5433067
  0.5194359   0.5759345   1.1175632  -0.15769468 -0.03366093  0.20415437
 -0.29673284 -0.02041271 -0.11859441 -0.08951158 -0.12095467  1.4493773
 -0.02670609 -0.08807869 -0.18080655  1.0772154  -0.14548595  0.98836994
  0.92493606  0.05515075  1.386848    0.09420443 -0.14315459 -0.0031108
 -0.07479127 -0.04568234  0.53781235 -0.05080849 -0.00991098 -0.10296568
 -0.31110397  0.57005084 -0.01275587 -0.16283672  0.39438438  0.921437
  0.5275656  -0.05461663  0.5369909  -0.10282931  0.39335608  0.13195741
 -0.09775955  0.05174184 -0.05361018 -0.11235242 -0.00569889  1.7991292
 -0.03021204 -0.15299277  1.5311794  -0.04167995 -0.05866696  1.2100899
 -0.16323255  1.4888885  -0.02033447 -0.00640607 -0.06315544 -0.0503192
  0.5178586  -0.12477712 -0.08271796 -0.06866742 -0.16047631  0.5696449
 -0.24685493 -0.1169958  -0.08677844  0.9023019  -0.0248492  -0.05225603
 -0.10909799 -0.00419017]
Outputs from 10 [<Conv2d Layer with in_channels 64, out_channels 128, weights with shape (128, 64, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d719a0>, <tinygrad.nn.LeakyReLU object at 0x112d71a30>] convolutional
[-0.03103969 -0.03139806 -0.03122684 -0.0311593  -0.03122692 -0.03115371
 -0.03118884 -0.03117647 -0.03118704 -0.03115344 -0.03111545 -0.03100474
 -0.03099639 -0.03098723 -0.03091621 -0.0311268  -0.0310892  -0.03103751
 -0.03112486 -0.03111466 -0.03102978 -0.03110538 -0.03127166 -0.03110967
 -0.03110071 -0.03111907 -0.03120852 -0.03117694 -0.03121214 -0.0310936
 -0.03120243 -0.03105686 -0.03101696 -0.03117932 -0.03111081 -0.03111838
 -0.03110425 -0.03108853 -0.03103065 -0.03107227 -0.03108654 -0.03104032
 -0.03111775 -0.03110424 -0.03111221 -0.03113778 -0.03119529 -0.0311983
 -0.03114422 -0.03119591 -0.03116336 -0.03111539 -0.0312025  -0.03124934
 -0.03124648 -0.03123842 -0.03117207 -0.03117935 -0.03120638 -0.03119684
 -0.03109689 -0.03117111 -0.03122597 -0.031122   -0.03100764 -0.03110998
 -0.03117684 -0.03123988 -0.03111883 -0.03120211 -0.03108929 -0.03116784
 -0.03115586 -0.03096597 -0.03108113 -0.03100956 -0.03103575 -0.03111112
 -0.03116033 -0.03100406 -0.03104064 -0.03107451 -0.03103603 -0.03098367
 -0.0311009  -0.03107421 -0.03106032 -0.03091465 -0.03108824 -0.03107846
 -0.03108254 -0.03103304 -0.03103746 -0.03119509 -0.03102471 -0.03112069
 -0.03099642 -0.03110137 -0.03094024 -0.03098226 -0.03094574 -0.03112806
 -0.03109341 -0.03111636]
Outputs from 11 [<tinygrad.nn.EmptyLayer object at 0x112d71fa0>] shortcut
[10.876173   3.812315   4.3469872  4.6283097  3.5212116  8.432359
  5.0290027  6.6583233  5.098454   7.3830514  5.084122   5.8124585
  6.9998517  9.072046   3.5149431  3.9634588  4.6622715  6.5416913
  4.672261   8.845146   8.453461  13.621006   6.108212  11.310895
  6.2408447  8.873529   7.1054773  7.437686   9.150245   5.9471416
  6.584785   6.948676   4.5822263  6.2283015  5.898984  10.012865
 12.8345785  5.9748073  3.4037793  9.127142   8.186779   4.7372103
  8.170673   7.5248423  9.0811825  5.689021   7.8610706  5.1469727
  6.83291    6.576209   7.8492565  9.357503   7.8217835  5.650635
  6.769671   7.255616   6.5225296  6.634353   5.664451   6.720599
  9.235521   6.5204206  9.440327   8.725973   9.397719   7.0551586
  4.6787157  7.236658   6.497052   4.274567   5.06265    5.925082
  4.2259145  4.375882   2.7834103  8.512533   5.2420115  3.9726012
  5.20421    7.752309   5.2509804  6.2062345  8.499113   3.202878
  6.1500893  5.6009007  3.0232885  7.246179   3.9206853  3.1463401
  5.2539825  4.4793506  3.9039323  3.4645882  6.2387676  3.7661633
  4.8849325  2.1149602  6.436599   4.898894   4.365636   5.5081086
  9.5311    11.660287 ]
Outputs from 12 [<Conv2d Layer with in_channels 128, out_channels 256, weights with shape (256, 128, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d8a040>, <tinygrad.nn.LeakyReLU object at 0x112d8a0d0>] convolutional
[-0.11405917 -0.13275038 -0.27980384 -0.05875355 -0.09746702 -0.09799708
 -0.10316538 -0.18702911 -0.06344014 -0.13115668 -0.1097331  -0.09915487
 -0.13896029 -0.01016712 -0.03978558 -0.06585103 -0.1191235  -0.17794453
 -0.00449327 -0.10530805 -0.02278855 -0.17957072 -0.04560684 -0.03472853
  0.03631878 -0.13789962 -0.05010706 -0.09923084 -0.04801667 -0.07156663
 -0.11371541 -0.14731985  0.22170556 -0.02414824 -0.0539979  -0.10422926
 -0.08805088 -0.14209996 -0.14881477 -0.11976462 -0.11136544 -0.02067569
 -0.06893289 -0.07073845 -0.04508971 -0.02043882 -0.08975672 -0.10660559
 -0.04729635 -0.12314904 -0.15830033 -0.05033933]
Outputs from 13 [<Conv2d Layer with in_channels 256, out_channels 128, weights with shape (128, 256, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d8a670>, <tinygrad.nn.LeakyReLU object at 0x112d8a700>] convolutional
[2.1961877  1.6945796  1.0113821  2.105092   0.80581737 1.2884066
 1.8855078  1.6560588  0.39608657 1.1037819  1.8202288  1.896141
 1.7000117  1.3990643  1.1705413  1.4478486  2.3905058  0.4447384
 2.183883   1.7045002  2.0546248  1.9155533  1.3791392  0.8397443
 2.2789989  1.7467391  2.264833   2.742861   2.3145473  2.3443203
 1.8054545  1.6934152  0.79581916 2.4411669  2.116415   2.3740878
 2.1690047  2.4741197  1.3608549  1.2329223  0.96007025 1.9464772
 2.4682865  1.9922132  2.2239563  2.3345227  2.151211   2.087849
 2.3649454  1.790344   2.7574492  2.2177546 ]
Outputs from 14 [<Conv2d Layer with in_channels 128, out_channels 256, weights with shape (256, 128, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d8aca0>, <tinygrad.nn.LeakyReLU object at 0x112d8ad30>] convolutional
[-0.06983955 -0.08229072 -0.05535931 -0.05784181 -0.03737075 -0.04387895
 -0.06635655 -0.04858806 -0.04280858 -0.05079094 -0.06405359 -0.06947659
 -0.05208255 -0.04060438 -0.03935231 -0.05194953 -0.03960621 -0.05245231
 -0.05420614 -0.0527979  -0.05929179 -0.06158457 -0.05666729 -0.05179029
 -0.05756043 -0.06021678 -0.04931118 -0.04653718 -0.0550127  -0.05423017
 -0.05744243 -0.05610282 -0.0612939  -0.05044648 -0.05711186 -0.04426129
 -0.04050319 -0.04823    -0.05120497 -0.0495776  -0.04948823 -0.04299464
 -0.05742476 -0.05497003 -0.05489705 -0.06044308 -0.05599026 -0.05855951
 -0.04724476 -0.0573745  -0.06839168 -0.08949871]
Outputs from 15 [<tinygrad.nn.EmptyLayer object at 0x112d8d2e0>] shortcut
[-0.18389872 -0.2150411  -0.33516315 -0.11659536 -0.13483778 -0.14187604
 -0.16952193 -0.23561718 -0.10624872 -0.18194762 -0.17378668 -0.16863146
 -0.19104284 -0.0507715  -0.07913788 -0.11780055 -0.1587297  -0.23039684
 -0.05869941 -0.15810595 -0.08208035 -0.2411553  -0.10227413 -0.08651882
 -0.02124165 -0.1981164  -0.09941824 -0.14576802 -0.10302937 -0.12579681
 -0.17115784 -0.20342268  0.16041166 -0.07459471 -0.11110976 -0.14849055
 -0.12855406 -0.19032997 -0.20001973 -0.16934222 -0.16085367 -0.06367033
 -0.12635764 -0.12570848 -0.09998676 -0.08088191 -0.14574698 -0.1651651
 -0.0945411  -0.18052354 -0.226692   -0.13983804]
Outputs from 16 [<Conv2d Layer with in_channels 256, out_channels 128, weights with shape (128, 256, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d8d340>, <tinygrad.nn.LeakyReLU object at 0x112d8d3d0>] convolutional
[4.3551283 6.546404  4.2123146 4.3070636 4.7212076 3.7891202 2.7560594
 2.977805  4.006989  4.0799723 3.4797163 3.1905303 3.70673   3.7666183
 4.3932533 4.2376056 4.803446  3.702396  4.3141036 3.9376779 3.8701544
 3.6922808 4.988206  4.359834  4.473513  4.290245  4.501083  6.1517153
 5.4163146 5.405403  4.1848464 4.167826  2.736297  4.1678753 5.0769224
 4.893848  4.599586  3.7743402 3.0341272 2.4775586 2.8413794 4.035227
 2.9601846 2.4065168 3.0990186 3.4380598 3.5920377 3.6936731 3.9513211
 2.3702266 2.8088994 2.23405  ]
Outputs from 17 [<Conv2d Layer with in_channels 128, out_channels 256, weights with shape (256, 128, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d8d970>, <tinygrad.nn.LeakyReLU object at 0x112d8da00>] convolutional
[-0.03668988 -0.04743978  0.39873797  0.30394423  0.59679586  0.600666
  0.20717299  0.640618    0.5247794   0.15213525  0.22034013  0.5029966
  0.46825808  0.49232846  0.37996334  0.39064676  0.16625744  0.44993728
  0.5469869   0.76779693  0.6598336   0.57456213  0.6701849   0.35417324
  0.17321128  0.54782706  0.37611264  0.8174439   0.9687633   0.6137511
  0.66948014  0.8173      0.28045487 -0.00514132  0.1157515   0.4479733
  0.66747874  0.52887267  0.34964192  0.653271    0.3404684   0.1318636
  0.41501147  0.24290764 -0.00944494  0.43512768  0.07645863  0.551573
  0.4951405   0.92188305  0.10439116  0.72876996]
Outputs from 18 [<tinygrad.nn.EmptyLayer object at 0x112d8df70>] shortcut
[-0.2205886  -0.26248088  0.06357482  0.18734887  0.46195808  0.45878994
  0.03765106  0.40500087  0.41853064 -0.02981237  0.04655345  0.33436516
  0.27721524  0.44155696  0.30082545  0.27284622  0.00752774  0.21954045
  0.48828748  0.60969096  0.57775325  0.33340684  0.5679108   0.26765442
  0.15196963  0.34971064  0.27669442  0.6716759   0.8657339   0.48795432
  0.4983223   0.61387736  0.44086653 -0.07973604  0.00464175  0.29948276
  0.5389247   0.3385427   0.14962219  0.4839288   0.17961474  0.06819326
  0.28865382  0.11719917 -0.1094317   0.35424578 -0.06928834  0.38640788
  0.4005994   0.7413595  -0.12230085  0.5889319 ]
Outputs from 19 [<Conv2d Layer with in_channels 256, out_channels 128, weights with shape (128, 256, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d8dfd0>, <tinygrad.nn.LeakyReLU object at 0x112d8e0a0>] convolutional
[-0.44565055 -0.5605411  -0.54099464 -0.3025603  -0.28210136 -0.22582836
 -0.32515168 -0.37902448 -0.18722913 -0.27682802 -0.30594584 -0.32739863
 -0.3266172  -0.13258366 -0.27007088 -0.3272613  -0.28405142 -0.32731795
 -0.4380562  -0.41570535 -0.37494308 -0.3580717  -0.3181622  -0.37535462
 -0.35154396 -0.41794124 -0.4706876  -0.42232066 -0.545633   -0.4681653
 -0.4007062  -0.4406599  -0.4231113  -0.41755667 -0.43572766 -0.4255353
 -0.45960894 -0.37854153 -0.3270285  -0.21814294 -0.20383058 -0.2860751
 -0.36431417 -0.34736943 -0.3220032  -0.4221843  -0.41395304 -0.464747
 -0.4328095  -0.47635826 -0.44877788 -0.42180586]
Outputs from 20 [<Conv2d Layer with in_channels 128, out_channels 256, weights with shape (256, 128, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d8e640>, <tinygrad.nn.LeakyReLU object at 0x112d8e6d0>] convolutional
[-0.1210709  -0.11355286  0.91662955 -0.07984498 -0.06969627 -0.06026573
 -0.038171    0.10430497 -0.08883532 -0.03292359 -0.07952221 -0.00897681
 -0.01803875 -0.05731777 -0.10410216 -0.11363985  0.16789809 -0.01373057
 -0.08923403  0.28852227 -0.03405327  0.06409988 -0.01842191 -0.08749259
 -0.07488805  0.2505314  -0.03144904 -0.04718854 -0.09316962  0.44952425
 -0.03840714  0.2518846  -0.06177789 -0.12994507 -0.06678706 -0.0519074
 -0.08146634  0.21764067 -0.01377065 -0.03846721 -0.00003933 -0.05552135
  0.3524184  -0.09585994 -0.06159247 -0.01910733 -0.04054388  0.3846065
 -0.06685054  1.3205177   0.03513938 -0.07054051]
Outputs from 21 [<tinygrad.nn.EmptyLayer object at 0x112d8ec40>] shortcut
[-0.3416595  -0.37603375  0.98020434  0.10750389  0.3922618   0.39852422
 -0.00051994  0.50930583  0.3296953  -0.06273595 -0.03296876  0.32538834
  0.2591765   0.3842392   0.19672328  0.15920638  0.17542583  0.20580988
  0.39905345  0.89821327  0.5437      0.3975067   0.5494889   0.18016183
  0.07708158  0.600242    0.24524538  0.6244874   0.7725643   0.93747854
  0.45991516  0.865762    0.37908864 -0.20968111 -0.06214532  0.24757536
  0.45745835  0.55618334  0.13585153  0.44546157  0.1795754   0.01267192
  0.6410722   0.02133923 -0.17102417  0.33513844 -0.10983223  0.7710144
  0.33374885  2.0618773  -0.08716147  0.51839143]
Outputs from 22 [<Conv2d Layer with in_channels 256, out_channels 128, weights with shape (128, 256, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d8eca0>, <tinygrad.nn.LeakyReLU object at 0x112d8ed30>] convolutional
[ 1.0630407  -0.09863145 -0.29163757 -0.14350869 -0.18733482 -0.18894438
 -0.01407195 -0.10512588 -0.19780622 -0.2826913  -0.14172754 -0.1515328
 -0.05087072 -0.18345806 -0.20329408 -0.13951668 -0.22529283 -0.11975084
 -0.18159781 -0.24529147 -0.1363511  -0.19397628 -0.29332128 -0.1413213
 -0.08771259 -0.08410511 -0.13972138 -0.12979293 -0.08234193 -0.19850287
 -0.32022795 -0.28215843 -0.12740359 -0.19745567 -0.09746019 -0.09908793
 -0.18781625 -0.12142358 -0.14164679 -0.23596811 -0.17487241 -0.15937589
 -0.15032646 -0.0975408  -0.12831017 -0.05942246 -0.14173646 -0.09456593
 -0.11302932 -0.20728612 -0.31146857  0.21181548]
Outputs from 23 [<Conv2d Layer with in_channels 128, out_channels 256, weights with shape (256, 128, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d90310>, <tinygrad.nn.LeakyReLU object at 0x112d903a0>] convolutional
[-0.07395826  0.49589574  0.25539583 -0.0915909  -0.16157614 -0.11950704
 -0.09784156 -0.13644175 -0.07920095 -0.13545649 -0.13617538 -0.16575168
 -0.11893339 -0.12785266 -0.16166839 -0.17293325 -0.11884568 -0.12392294
 -0.12791865 -0.15079682 -0.18874125 -0.15544258 -0.10018957 -0.13295422
 -0.07574531 -0.13658145 -0.15475295 -0.07485604 -0.09005512 -0.09374901
  0.12350345 -0.12651038 -0.05566034 -0.11908149 -0.1032841  -0.17974041
 -0.153895   -0.15384923 -0.13458386 -0.1790254  -0.1714641  -0.20357732
 -0.13803735 -0.1722588  -0.13186276 -0.20489672 -0.1683314  -0.17838179
 -0.13549142 -0.09860577 -0.05248609 -0.07425247]
Outputs from 24 [<tinygrad.nn.EmptyLayer object at 0x112d90910>] shortcut
[-0.41561776  0.11986199  1.2356002   0.01591299  0.23068567  0.27901718
 -0.09836151  0.37286407  0.25049436 -0.19819245 -0.16914414  0.15963666
  0.1402431   0.25638652  0.03505489 -0.01372688  0.05658015  0.08188694
  0.2711348   0.74741644  0.3549587   0.24206413  0.44929934  0.04720761
  0.00133627  0.46366057  0.09049243  0.54963136  0.6825092   0.84372956
  0.5834186   0.7392516   0.3234283  -0.3287626  -0.16542941  0.06783494
  0.30356336  0.4023341   0.00126767  0.26643616  0.0081113  -0.1909054
  0.50303483 -0.15091956 -0.30288693  0.13024172 -0.2781636   0.5926326
  0.19825743  1.9632715  -0.13964756  0.44413894]
Outputs from 25 [<Conv2d Layer with in_channels 256, out_channels 128, weights with shape (128, 256, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d90970>, <tinygrad.nn.LeakyReLU object at 0x112d90a00>] convolutional
[ 0.5921602   0.717698   -0.06956183  0.26896355  0.32584894  1.066453
  1.4037559   0.80480576  1.2949622   1.4372735   1.546306    0.9982039
  0.7672326   0.46952534  0.63387007  1.1453123   1.7567912   0.2201118
  0.28022137 -0.01485866  0.88520205  0.42716384  0.04314128 -0.03212939
  1.3104966   0.25709787 -0.02796642 -0.01249524  0.11595508  0.14275712
 -0.02038943 -0.01466705  0.27510488  0.04340929  0.47906995  0.30428585
  0.15911318  0.75541973  1.0301431   0.7187362   0.6612983   0.59407103
  0.768922    0.95380646  0.48456597  1.0907965   0.85074794  0.4160241
  1.2756857   0.3463062   1.7798003   1.6279191 ]
Outputs from 26 [<Conv2d Layer with in_channels 128, out_channels 256, weights with shape (256, 128, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d90fa0>, <tinygrad.nn.LeakyReLU object at 0x112d92070>] convolutional
[ 2.366126    0.9458838  -0.18169467  0.9956165   2.3021953   0.81991
 -0.04106034  0.7042488   2.4760087   1.2967956   1.047311    1.1306041
  0.2873833   0.6712937   1.9475608   1.3498454   0.8479433   0.21182707
  1.4467968   0.8407611   0.9607757   0.65638924  0.86662096  2.2479153
  1.4008447  -0.10687675  0.7384867   2.4016833   1.3604965  -0.03193909
 -0.07154263 -0.003015    1.0601175   1.1541725   0.8013453   1.8382828
  0.46349597  0.49293733 -0.0606148   0.01537976  1.1086398   1.1771885
  0.83863515  1.3360213   1.6271462   1.1693436   0.6877024  -0.01725209
  0.2184336  -0.10355026  0.20484978 -0.03699295]
Outputs from 27 [<tinygrad.nn.EmptyLayer object at 0x112d925e0>] shortcut
[ 1.9505084   1.0657458   1.0539056   1.0115294   2.532881    1.0989271
 -0.13942185  1.0771129   2.726503    1.0986031   0.8781668   1.2902408
  0.42762637  0.9276802   1.9826157   1.3361186   0.90452343  0.29371402
  1.7179315   1.5881776   1.3157344   0.89845335  1.3159204   2.2951229
  1.4021809   0.3567838   0.82897913  2.9513147   2.0430057   0.81179047
  0.511876    0.73623663  1.3835458   0.82540995  0.6359159   1.9061178
  0.7670593   0.8952714  -0.05934713  0.28181592  1.1167512   0.9862831
  1.34167     1.1851017   1.3242593   1.2995853   0.4095388   0.5753805
  0.41669104  1.8597212   0.06520222  0.407146  ]
Outputs from 28 [<Conv2d Layer with in_channels 256, out_channels 128, weights with shape (128, 256, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d92640>, <tinygrad.nn.LeakyReLU object at 0x112d926d0>] convolutional
[-0.325677   -0.61350363 -0.4589959  -0.31930918 -0.27002233 -0.1590291
 -0.11411134 -0.21965277 -0.28993896 -0.22424228 -0.22437249 -0.22276449
 -0.1834172  -0.16667049 -0.27410796 -0.23362832 -0.23133588 -0.18785481
 -0.26076922 -0.25581178 -0.19699177 -0.2130221  -0.30537197 -0.2524989
 -0.21733163 -0.2099074  -0.29719603 -0.377899   -0.31097713 -0.22790392
 -0.20350409 -0.1803341  -0.06790663 -0.19164371 -0.2937646  -0.28426513
 -0.19042479 -0.16787751 -0.16435656 -0.19122754 -0.19543509 -0.16341613
 -0.21370696 -0.11611395 -0.16233432 -0.2606318  -0.20681646 -0.20170815
 -0.17596623 -0.07826056 -0.2478982  -0.1524442 ]
Outputs from 29 [<Conv2d Layer with in_channels 128, out_channels 256, weights with shape (256, 128, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d92c70>, <tinygrad.nn.LeakyReLU object at 0x112d92d00>] convolutional
[ 0.44370675 -0.50208133 -0.2537237  -0.12860186 -0.08905043 -0.08526542
 -0.09364987  0.39556277 -0.10086431 -0.1652344  -0.05255736 -0.08675351
 -0.06097033 -0.10730316 -0.17795284 -0.09694057 -0.18176441 -0.05616237
  0.0974108  -0.13192771 -0.06841745 -0.07646518 -0.07862405 -0.16948678
 -0.11303611 -0.11507135  0.2723875  -0.15566784 -0.16310306 -0.17250955
 -0.15881644 -0.12101301 -0.12994981 -0.08710465 -0.1258161  -0.14471154
 -0.173996   -0.11935434 -0.09128311  0.26684582 -0.04171468 -0.07236541
 -0.09430244 -0.03626708 -0.04493463 -0.05519335 -0.150066   -0.06593448
 -0.18821527 -0.03677072 -0.164021   -0.13831526]
Outputs from 30 [<tinygrad.nn.EmptyLayer object at 0x112d942b0>] shortcut
[ 2.394215    0.5636645   0.80018187  0.8829276   2.4438305   1.0136617
 -0.23307171  1.4726757   2.6256385   0.93336874  0.82560945  1.2034873
  0.36665604  0.82037705  1.8046628   1.2391781   0.722759    0.23755164
  1.8153423   1.4562498   1.247317    0.82198817  1.2372963   2.125636
  1.2891448   0.24171245  1.1013666   2.795647    1.8799026   0.6392809
  0.35305953  0.61522365  1.253596    0.73830533  0.51009977  1.7614063
  0.59306335  0.77591705 -0.15063024  0.5486617   1.0750365   0.9139177
  1.2473676   1.1488347   1.2793247   1.244392    0.2594728   0.509446
  0.22847576  1.8229505  -0.09881878  0.26883075]
Outputs from 31 [<Conv2d Layer with in_channels 256, out_channels 128, weights with shape (128, 256, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d94310>, <tinygrad.nn.LeakyReLU object at 0x112d943a0>] convolutional
[ 1.7754154   1.1362603   0.30728203 -0.00305773  0.64511573  0.10322145
  0.9327859   1.0386415  -0.03621191  1.139354    0.10135436 -0.02927405
  0.9667919   0.0066126   0.4790945  -0.02640971  0.5338537   1.6608434
  0.00547996  0.71473664  0.75566286  1.2700012  -0.05203029  1.141861
  2.8853498   1.8324554   1.1247268   1.0966814   0.6668305   1.8264072
 -0.05261384 -0.11069734  2.2404785   1.5485218   2.0331573   1.0958798
  0.93006593 -0.04454667  0.66426957 -0.01146859  1.8297138   0.94462496
  0.08381668  1.7874053   0.7397916   0.03384906  1.3411901   0.5866784
  0.5946966   0.06780311  1.9562092   0.02208877]
Outputs from 32 [<Conv2d Layer with in_channels 128, out_channels 256, weights with shape (256, 128, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d94940>, <tinygrad.nn.LeakyReLU object at 0x112d949d0>] convolutional
[ 0.5631741  -0.13313915  0.18286347  0.19140768 -0.12369557 -0.1738745
 -0.07497056  1.1026661  -0.09112406 -0.02886369 -0.06586897 -0.1657819
 -0.00114873  0.01735419 -0.10874434 -0.06278219 -0.24044137  0.70003974
 -0.09006964 -0.03121432 -0.12714985  0.05506587  0.07597369 -0.09623583
 -0.1747369   1.690161   -0.09078921 -0.13106543 -0.07663429 -0.04079299
  0.21196556  1.2537005   0.79473317  0.81419384 -0.02170354 -0.0912913
 -0.12022813 -0.05390344 -0.17777026  0.35203803 -0.09645268 -0.02857618
 -0.13710995 -0.04258133 -0.0584389  -0.10352819 -0.08494132 -0.01894571
  0.01970297 -0.10905766 -0.01896687 -0.22555812]
Outputs from 33 [<tinygrad.nn.EmptyLayer object at 0x112d94f40>] shortcut
[ 2.9573894   0.43052536  0.98304534  1.0743353   2.3201349   0.83978724
 -0.3080423   2.5753417   2.5345144   0.9045051   0.7597405   1.0377054
  0.3655073   0.83773124  1.6959184   1.1763959   0.48231763  0.9375914
  1.7252727   1.4250355   1.1201671   0.87705404  1.3132701   2.0294003
  1.1144079   1.9318734   1.0105774   2.6645815   1.8032683   0.5984879
  0.5650251   1.8689241   2.048329    1.5524992   0.48839623  1.670115
  0.47283524  0.7220136  -0.3284005   0.90069973  0.9785838   0.8853415
  1.1102576   1.1062534   1.2208858   1.1408639   0.17453146  0.49050033
  0.24817874  1.7138928  -0.11778565  0.04327263]
Outputs from 34 [<Conv2d Layer with in_channels 256, out_channels 128, weights with shape (128, 256, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d94fa0>, <tinygrad.nn.LeakyReLU object at 0x112d96070>] convolutional
[-0.27469543 -0.18092899 -0.19078903 -0.01372668 -0.07363657 -0.08571147
 -0.08972744 -0.12920079 -0.06395859  0.06198192 -0.18350272 -0.14933519
 -0.12944467 -0.03398845 -0.05405951 -0.03872264 -0.07619374 -0.15217271
 -0.1796312  -0.0867718  -0.0924704  -0.17371799 -0.18952039 -0.12370332
  0.90973175 -0.16766283  0.4800252  -0.07762457 -0.15050642  0.21822491
 -0.14812373 -0.16044916  0.0371716   0.7588923  -0.073394   -0.06226667
 -0.1244128  -0.03524798 -0.15619214 -0.15879846 -0.22215998 -0.07770577
 -0.11333261 -0.11589155 -0.04224611 -0.12157531 -0.08161851 -0.08805722
 -0.03608149 -0.05434896 -0.00273689 -0.1062391 ]
Outputs from 35 [<Conv2d Layer with in_channels 128, out_channels 256, weights with shape (256, 128, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d96610>, <tinygrad.nn.LeakyReLU object at 0x112d966a0>] convolutional
[ 0.94931257  0.59995425 -0.00318458 -0.08988087 -0.1666185  -0.11481587
 -0.00860162 -0.15973476 -0.07593655 -0.06358092 -0.07228213  0.2295034
 -0.0154955  -0.09499538 -0.20862018 -0.06608951  0.25056517  0.3403741
 -0.18851256 -0.07455602 -0.14091842 -0.07059276 -0.0542107  -0.11287526
  0.5446886   2.9656236  -0.15758446 -0.09209461 -0.01314415  1.0106539
  0.80577576  0.24188417 -0.0295053  -0.08150852 -0.06158742 -0.0617272
 -0.00904768 -0.02063686 -0.01147078 -0.09699571 -0.1202518  -0.13631976
 -0.03892001 -0.06342627 -0.02411116  0.37193263  0.05818981 -0.07584506
  0.370039   -0.0648111   0.00856155  0.07489467]
Outputs from 36 [<tinygrad.nn.EmptyLayer object at 0x112d96c10>] shortcut
[ 3.906702    1.0304797   0.9798608   0.98445445  2.1535163   0.72497135
 -0.3166439   2.415607    2.4585779   0.84092414  0.68745834  1.2672088
  0.3500118   0.74273586  1.4872983   1.1103064   0.7328828   1.2779655
  1.5367601   1.3504795   0.9792487   0.8064613   1.2590594   1.9165251
  1.6590965   4.897497    0.852993    2.5724869   1.7901242   1.6091418
  1.3708009   2.1108084   2.0188239   1.4709907   0.4268088   1.6083878
  0.46378756  0.70137674 -0.33987126  0.803704    0.85833204  0.74902177
  1.0713376   1.0428271   1.1967746   1.5127965   0.23272127  0.41465527
  0.6182177   1.6490817  -0.1092241   0.1181673 ]
Outputs from 37 [<Conv2d Layer with in_channels 256, out_channels 512, weights with shape (512, 256, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d96c70>, <tinygrad.nn.LeakyReLU object at 0x112d96d00>] convolutional
[-0.43152353 -0.26896557 -0.27811608 -0.24025662 -0.15543059 -0.28742036
 -0.22790284 -0.20356803 -0.32262844 -0.2850468  -0.22878979 -0.26145813
 -0.2768389  -0.2594519  -0.36428532 -0.32626733 -0.19315813 -0.22265606
 -0.22161661 -0.27333805 -0.27362928 -0.32553053 -0.22837058 -0.29744276
 -0.31440505 -0.10234578]
Outputs from 38 [<Conv2d Layer with in_channels 512, out_channels 256, weights with shape (256, 512, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d992e0>, <tinygrad.nn.LeakyReLU object at 0x112d99370>] convolutional
[-0.1206049  -0.08517815 -0.09182347 -0.06558796 -0.09369659 -0.01911626
 -0.02148576  0.18738794 -0.12393632  0.39683533 -0.03394625 -0.10039771
 -0.14718257 -0.05946035 -0.05945278 -0.05067394 -0.13735212 -0.09050246
 -0.06822956 -0.07346131 -0.08351388 -0.03695576 -0.00436781 -0.00512782
 -0.1174235  -0.23270746]
Outputs from 39 [<Conv2d Layer with in_channels 256, out_channels 512, weights with shape (512, 256, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d99910>, <tinygrad.nn.LeakyReLU object at 0x112d999a0>] convolutional
[-0.04852801 -0.04850978 -0.04850892 -0.04849223 -0.04850604 -0.0485051
 -0.04851366 -0.04851533 -0.04851127 -0.04850983 -0.04850817 -0.04849942
 -0.04850126 -0.04850304 -0.04851427 -0.04852586 -0.04851338 -0.04850986
 -0.04851579 -0.04853233 -0.04853888 -0.04852442 -0.04850435 -0.0484912
 -0.04850787 -0.04852164]
Outputs from 40 [<tinygrad.nn.EmptyLayer object at 0x112d99f10>] shortcut
[-0.48005155 -0.31747535 -0.326625   -0.28874886 -0.20393662 -0.33592546
 -0.2764165  -0.25208336 -0.3711397  -0.33355662 -0.27729797 -0.30995753
 -0.32534015 -0.30795494 -0.4127996  -0.3747932  -0.24167152 -0.2711659
 -0.2701324  -0.3218704  -0.32216817 -0.37405494 -0.27687493 -0.34593397
 -0.36291292 -0.15086742]
Outputs from 41 [<Conv2d Layer with in_channels 512, out_channels 256, weights with shape (256, 512, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d99f70>, <tinygrad.nn.LeakyReLU object at 0x112d9a040>] convolutional
[ 0.8704231   0.35450745  0.7282543  -0.08941897  0.0367474   0.16021389
 -0.00597089  0.2986762  -0.04296365 -0.06690904 -0.02635527 -0.06980523
 -0.12465782  0.49823892  1.2456536  -0.13557617 -0.08536252  0.7895235
  0.9327028  -0.0136116  -0.04321265 -0.06454515 -0.00510705 -0.00038142
  0.27407604 -0.18331145]
Outputs from 42 [<Conv2d Layer with in_channels 256, out_channels 512, weights with shape (512, 256, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d9a5e0>, <tinygrad.nn.LeakyReLU object at 0x112d9a670>] convolutional
[-0.05557934  0.6200199   0.30237988  0.08709285 -0.00028698 -0.00583825
 -0.02320661  0.01069844  0.12993822 -0.05083305  0.10474488  0.3014253
 -0.01912575 -0.06520367 -0.00633112 -0.06295199 -0.0629408  -0.01024381
  0.03894016  0.14097467  0.12281242 -0.00672133 -0.02540183  0.04408994
 -0.03867551 -0.06624299]
Outputs from 43 [<tinygrad.nn.EmptyLayer object at 0x112d9abe0>] shortcut
[-0.5356309   0.30254456 -0.02424511 -0.20165601 -0.2042236  -0.3417637
 -0.29962313 -0.24138492 -0.24120149 -0.38438967 -0.17255309 -0.00853223
 -0.3444659  -0.3731586  -0.4191307  -0.43774518 -0.3046123  -0.2814097
 -0.23119223 -0.18089572 -0.19935575 -0.3807763  -0.30227676 -0.30184403
 -0.40158844 -0.21711041]
Outputs from 44 [<Conv2d Layer with in_channels 512, out_channels 256, weights with shape (256, 512, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d9ac40>, <tinygrad.nn.LeakyReLU object at 0x112d9acd0>] convolutional
[ 1.3589525  -0.07464343  0.2401952   0.08197016  0.48309302  0.47419077
  0.5372126   0.40295672  0.33323306  0.6851506   0.59073895  0.74866325
  0.40221626  0.54920256  0.42906553  0.7126402   0.88121444  0.20338832
  0.2784397   0.43761367  0.68020225  0.7597405   0.4151048   0.2611993
  0.44474697  0.23658396]
Outputs from 45 [<Conv2d Layer with in_channels 256, out_channels 512, weights with shape (512, 256, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d9e2b0>, <tinygrad.nn.LeakyReLU object at 0x112d9e340>] convolutional
[-0.06944298 -0.08812546 -0.09018456 -0.06301565 -0.03792356 -0.04237041
 -0.05352571 -0.04396742 -0.032909   -0.0393043  -0.04572209 -0.04114299
 -0.0431121  -0.0468487  -0.04724286 -0.06611726 -0.05228161 -0.05226191
 -0.05284419 -0.04664264 -0.05616846 -0.05188813 -0.05359275 -0.04842098
 -0.03057252 -0.05301963]
Outputs from 46 [<tinygrad.nn.EmptyLayer object at 0x112d9e8b0>] shortcut
[-0.60507387  0.2144191  -0.11442968 -0.26467165 -0.24214716 -0.3841341
 -0.35314885 -0.28535235 -0.2741105  -0.42369395 -0.21827519 -0.04967521
 -0.387578   -0.4200073  -0.46637356 -0.50386244 -0.35689393 -0.33367163
 -0.28403643 -0.22753835 -0.25552422 -0.43266442 -0.3558695  -0.350265
 -0.43216097 -0.27013004]
Outputs from 47 [<Conv2d Layer with in_channels 512, out_channels 256, weights with shape (256, 512, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d9e910>, <tinygrad.nn.LeakyReLU object at 0x112d9e9a0>] convolutional
[-0.08582266 -0.17950709 -0.1624436  -0.17709057 -0.2416203  -0.0095274
 -0.07102783 -0.11122816 -0.21508351 -0.02974444 -0.08722674 -0.11379042
 -0.16084896 -0.10644418 -0.10530312 -0.06465149 -0.10855482 -0.14071058
 -0.13824044 -0.08929125 -0.07957581 -0.09809982 -0.10914136 -0.05318706
 -0.10347871 -0.18594098]
Outputs from 48 [<Conv2d Layer with in_channels 256, out_channels 512, weights with shape (512, 256, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d9ef40>, <tinygrad.nn.LeakyReLU object at 0x112d9efd0>] convolutional
[-0.1183294  -0.11605584 -0.01964121 -0.08428963 -0.0495486  -0.05485121
 -0.00752612 -0.04851214 -0.05106793  0.01754111 -0.00601542 -0.03708301
 -0.0415242  -0.01561118 -0.03593708 -0.06187118 -0.00607325  0.32702005
 -0.02496827 -0.05443255 -0.03686054 -0.03867964 -0.01689067 -0.04946551
 -0.0592283  -0.03697379]
Outputs from 49 [<tinygrad.nn.EmptyLayer object at 0x112d9f580>] shortcut
[-0.7234033   0.09836326 -0.13407089 -0.3489613  -0.29169577 -0.43898532
 -0.36067498 -0.33386448 -0.3251784  -0.40615284 -0.22429061 -0.08675822
 -0.4291022  -0.43561846 -0.50231063 -0.5657336  -0.36296716 -0.00665158
 -0.3090047  -0.2819709  -0.29238474 -0.47134405 -0.37276018 -0.3997305
 -0.49138927 -0.3071038 ]
Outputs from 50 [<Conv2d Layer with in_channels 512, out_channels 256, weights with shape (256, 512, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112d9f5e0>, <tinygrad.nn.LeakyReLU object at 0x112d9f670>] convolutional
[ 4.2883167  -0.18627794 -0.06749797 -0.05427995 -0.12547527  0.09848487
 -0.03768246 -0.09028579 -0.03114077  0.26335096 -0.05359608 -0.08362054
 -0.09766268 -0.09299621 -0.09731991 -0.1185592   0.40457618 -0.0204665
 -0.05787976  0.2704444  -0.00177612  0.12965244  0.09500629 -0.01970348
 -0.00168526  0.6184274 ]
Outputs from 51 [<Conv2d Layer with in_channels 256, out_channels 512, weights with shape (512, 256, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112d9fc10>, <tinygrad.nn.LeakyReLU object at 0x112d9fca0>] convolutional
[-0.18485396 -0.05209618 -0.15940323 -0.04415795 -0.00217161  0.18899167
 -0.08927771 -0.1316282   0.5157076   0.04644865 -0.08438633 -0.0392506
  0.09381735 -0.01185678 -0.06251822  0.17187274  0.45590746 -0.08392855
 -0.06130785 -0.04584758 -0.03839394 -0.01888957 -0.10875554 -0.19174862
 -0.12246668 -0.02292867]
Outputs from 52 [<tinygrad.nn.EmptyLayer object at 0x112da1250>] shortcut
[-0.90825725  0.04626708 -0.29347414 -0.39311925 -0.29386738 -0.24999365
 -0.4499527  -0.46549267  0.1905292  -0.3597042  -0.30867696 -0.12600882
 -0.33528486 -0.44747525 -0.5648289  -0.39386088  0.0929403  -0.09058013
 -0.37031254 -0.32781845 -0.3307787  -0.49023363 -0.4815157  -0.5914791
 -0.61385596 -0.33003247]
Outputs from 53 [<Conv2d Layer with in_channels 512, out_channels 256, weights with shape (256, 512, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112da12b0>, <tinygrad.nn.LeakyReLU object at 0x112da1340>] convolutional
[-0.16086257 -0.146363   -0.06675594 -0.09947436 -0.12077147 -0.15753043
 -0.07947179 -0.09622449 -0.14382327 -0.16670692 -0.08136737 -0.11994474
 -0.08028609 -0.07170502 -0.14401999 -0.08218376 -0.14940433 -0.13513966
 -0.09170604 -0.09409247 -0.08648404 -0.08904532 -0.10991319 -0.11041898
 -0.20394884 -0.1014421 ]
Outputs from 54 [<Conv2d Layer with in_channels 256, out_channels 512, weights with shape (512, 256, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112da18e0>, <tinygrad.nn.LeakyReLU object at 0x112da1970>] convolutional
[-0.01259185  0.7811059  -0.05335122  0.1462537   0.89857185  0.26426554
  0.21217632  0.9531748   0.42599225 -0.03352285  0.04158217  0.40286636
  0.799888    0.7470163   0.88394666  0.8514018  -0.01160702  0.48387098
  1.1136634   0.6797792   0.6397152   0.47794187  0.76551425  0.52540565
  0.24400055 -0.06090922]
Outputs from 55 [<tinygrad.nn.EmptyLayer object at 0x112da1ee0>] shortcut
[-0.9208491   0.82737297 -0.34682536 -0.24686554  0.6047045   0.01427189
 -0.23777637  0.48768216  0.6165215  -0.39322704 -0.2670948   0.27685755
  0.46460316  0.29954106  0.31911778  0.45754093  0.08133328  0.39329085
  0.74335086  0.35196072  0.3089365  -0.01229176  0.28399855 -0.06607348
 -0.3698554  -0.39094168]
Outputs from 56 [<Conv2d Layer with in_channels 512, out_channels 256, weights with shape (256, 512, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112da1f40>, <tinygrad.nn.LeakyReLU object at 0x112da1fd0>] convolutional
[ 1.0832825  -0.00077933  0.06878123 -0.04277297 -0.02840479  0.25265777
  0.6449472   0.25158718 -0.00897619 -0.05348564  0.25236714  0.54126596
 -0.02791147 -0.01894726  0.00794189 -0.02195139  0.25257516  0.5746031
 -0.01507811  0.28628746  0.28765258  0.11008158  0.11075377  0.20758408
  0.05614755  0.6491163 ]
Outputs from 57 [<Conv2d Layer with in_channels 256, out_channels 512, weights with shape (512, 256, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112da45b0>, <tinygrad.nn.LeakyReLU object at 0x112da4640>] convolutional
[ 2.9204814  -0.01338686 -0.1467979  -0.06708069 -0.11805417  0.16113484
 -0.03231116 -0.07056234  0.27767134 -0.06468754 -0.12627582 -0.10815389
  0.54611826 -0.05021173  0.02943558 -0.0161184  -0.08181041 -0.18478118
 -0.15232533 -0.1014846  -0.08879641 -0.03854254 -0.0337069   0.1645571
 -0.09855833  0.5881741 ]
Outputs from 58 [<tinygrad.nn.EmptyLayer object at 0x112da4bb0>] shortcut
[ 1.9996324   0.8139861  -0.49362326 -0.31394625  0.48665032  0.17540672
 -0.27008754  0.41711983  0.8941928  -0.4579146  -0.39337063  0.16870366
  1.0107214   0.24932933  0.34855336  0.44142252 -0.00047714  0.20850967
  0.59102553  0.25047612  0.2201401  -0.05083429  0.25029165  0.09848362
 -0.46841374  0.19723243]
Outputs from 59 [<Conv2d Layer with in_channels 512, out_channels 256, weights with shape (256, 512, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112da4c10>, <tinygrad.nn.LeakyReLU object at 0x112da4ca0>] convolutional
[ 0.48872882 -0.04866287 -0.03225156 -0.0826835  -0.09249245 -0.07632355
 -0.06241796 -0.0607717  -0.0799395  -0.10286698 -0.07135697 -0.07678439
 -0.09124116 -0.11033179 -0.08534328 -0.12208197 -0.08247149 -0.0661052
 -0.06488646 -0.04568876 -0.06421625 -0.04762607 -0.03240925 -0.05249112
 -0.08164933 -0.13227959]
Outputs from 60 [<Conv2d Layer with in_channels 256, out_channels 512, weights with shape (512, 256, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112da5280>, <tinygrad.nn.LeakyReLU object at 0x112da5310>] convolutional
[-0.05627111 -0.3352542  -0.03625622 -0.06757086 -0.10231332 -0.13517943
 -0.07528847 -0.1282463  -0.08631434 -0.10126    -0.08290466 -0.08665214
 -0.04386363 -0.01521495 -0.12664866 -0.08432919 -0.12175407 -0.09473301
 -0.08936262 -0.08916441 -0.05962441 -0.07113662 -0.05716671 -0.04692823
 -0.04159944  0.20871407]
Outputs from 61 [<tinygrad.nn.EmptyLayer object at 0x112da5880>] shortcut
[ 1.9433613   0.47873193 -0.52987945 -0.3815171   0.384337    0.04022729
 -0.345376    0.28887352  0.8078785  -0.5591746  -0.4762753   0.08205152
  0.9668578   0.23411438  0.2219047   0.35709333 -0.12223121  0.11377666
  0.5016629   0.16131172  0.1605157  -0.12197091  0.19312494  0.05155539
 -0.51001316  0.4059465 ]
Outputs from 62 [<Conv2d Layer with in_channels 512, out_channels 1024, weights with shape (1024, 512, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112da58e0>, <tinygrad.nn.LeakyReLU object at 0x112da5970>] convolutional
[-0.19394062 -0.1028618  -0.03547483 -0.12827317 -0.08341871 -0.13711731
 -0.04083655 -0.08277258 -0.11373498 -0.09315559 -0.08760035 -0.08572643
 -0.06109513]
Outputs from 63 [<Conv2d Layer with in_channels 1024, out_channels 512, weights with shape (512, 1024, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112da5f10>, <tinygrad.nn.LeakyReLU object at 0x112da5fa0>] convolutional
[-0.00746107 -0.00168699  0.05857021  0.09606177  0.24095565  0.3601194
  0.06876251  0.31843275 -0.02914566  0.03788805 -0.05467287 -0.02842952
  0.35001147]
Outputs from 64 [<Conv2d Layer with in_channels 512, out_channels 1024, weights with shape (1024, 512, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112da8580>, <tinygrad.nn.LeakyReLU object at 0x112da8610>] convolutional
[-0.03054801 -0.030582   -0.0305644  -0.03056377 -0.03056407 -0.03056405
 -0.0305641  -0.03056432 -0.03056361 -0.03056423 -0.03056397 -0.03056419
 -0.03056202]
Outputs from 65 [<tinygrad.nn.EmptyLayer object at 0x112da8b80>] shortcut
[-0.22448863 -0.1334438  -0.06603923 -0.15883695 -0.11398278 -0.16768137
 -0.07140066 -0.1133369  -0.14429858 -0.12371982 -0.11816432 -0.11629062
 -0.09165715]
Outputs from 66 [<Conv2d Layer with in_channels 1024, out_channels 512, weights with shape (512, 1024, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112da8be0>, <tinygrad.nn.LeakyReLU object at 0x112da8c70>] convolutional
[ 0.75596863 -0.02508711 -0.00262029 -0.03754198 -0.05240383 -0.02486329
 -0.03509301 -0.02289176 -0.02513607 -0.03107005 -0.05707454 -0.06307983
 -0.04887636]
Outputs from 67 [<Conv2d Layer with in_channels 512, out_channels 1024, weights with shape (1024, 512, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112daa250>, <tinygrad.nn.LeakyReLU object at 0x112daa2e0>] convolutional
[-0.09827421  0.03117871  0.36608595  0.5952459   0.76898426  0.57721144
  0.24903262  0.23034865  0.11915103  0.23788667  0.36601996  1.0945287
  0.40233815]
Outputs from 68 [<tinygrad.nn.EmptyLayer object at 0x112daa850>] shortcut
[-0.32276285 -0.10226509  0.3000467   0.43640894  0.65500146  0.40953007
  0.17763196  0.11701175 -0.02514756  0.11416685  0.24785565  0.97823805
  0.310681  ]
Outputs from 69 [<Conv2d Layer with in_channels 1024, out_channels 512, weights with shape (512, 1024, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112daa8b0>, <tinygrad.nn.LeakyReLU object at 0x112daa940>] convolutional
[ 1.4126014  -0.22514129 -0.04549257 -0.01380626 -0.00415206 -0.00953991
  0.25658858  0.30333742  0.26292753  0.06467301 -0.03510177 -0.04027424
  1.0993512 ]
Outputs from 70 [<Conv2d Layer with in_channels 512, out_channels 1024, weights with shape (1024, 512, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112daaee0>, <tinygrad.nn.LeakyReLU object at 0x112daaf70>] convolutional
[-0.01201131 -0.19057685 -0.03138573 -0.08983114 -0.04158252 -0.0056594
 -0.00141014 -0.01943476 -0.0143185  -0.04396802 -0.04811248 -0.04357691
  0.06420416]
Outputs from 71 [<tinygrad.nn.EmptyLayer object at 0x112dac520>] shortcut
[-0.33477417 -0.29284194  0.26866096  0.3465778   0.61341894  0.40387067
  0.17622182  0.09757698 -0.03946606  0.07019883  0.19974317  0.93466115
  0.37488514]
Outputs from 72 [<Conv2d Layer with in_channels 1024, out_channels 512, weights with shape (512, 1024, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112dac580>, <tinygrad.nn.LeakyReLU object at 0x112dac610>] convolutional
[ 0.30210704 -0.0694859   0.10501307  0.4344407   0.23731452  0.14047089
  0.16212073  0.16851893  0.06228533  0.2930643   0.14456564  0.7403852
  0.27589214]
Outputs from 73 [<Conv2d Layer with in_channels 512, out_channels 1024, weights with shape (1024, 512, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112dacbb0>, <tinygrad.nn.LeakyReLU object at 0x112dacc40>] convolutional
[-0.05730956  0.3386445  -0.03471757  0.15798503 -0.0330374  -0.08590022
 -0.04178602 -0.02799307 -0.01261374 -0.01966605 -0.02949263  0.20890927
 -0.05474149]
Outputs from 74 [<tinygrad.nn.EmptyLayer object at 0x112daf1f0>] shortcut
[-0.39208373  0.04580256  0.2339434   0.50456285  0.5803815   0.31797045
  0.1344358   0.06958391 -0.0520798   0.05053277  0.17025054  1.1435704
  0.32014364]
Outputs from 75 [<Conv2d Layer with in_channels 1024, out_channels 512, weights with shape (512, 1024, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112daf250>, <tinygrad.nn.LeakyReLU object at 0x112daf2e0>] convolutional
[ 2.1680398  -0.13360113 -0.05509089 -0.08991908  0.16619992  0.08041879
 -0.03449202 -0.01102507  0.2388477   0.3088472  -0.01441545 -0.01425592
  2.3652453 ]
Outputs from 76 [<Conv2d Layer with in_channels 512, out_channels 1024, weights with shape (1024, 512, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112daf880>, <tinygrad.nn.LeakyReLU object at 0x112daf910>] convolutional
[-0.12113378 -0.14926627 -0.0644272  -0.04347332 -0.08441912 -0.09407501
 -0.10661203 -0.11611865 -0.11061446 -0.18538265 -0.17842354 -0.08592537
 -0.1778075 ]
Outputs from 77 [<Conv2d Layer with in_channels 1024, out_channels 512, weights with shape (512, 1024, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112dafeb0>, <tinygrad.nn.LeakyReLU object at 0x112daff40>] convolutional
[ 3.268711   -0.18346715  0.67618155  0.34891737  0.39094818  0.70305693
  0.4717657  -0.03259299 -0.05579288  0.12041563 -0.0748015  -0.1894172
 -0.4923284 ]
Outputs from 78 [<Conv2d Layer with in_channels 512, out_channels 1024, weights with shape (1024, 512, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112db2520>, <tinygrad.nn.LeakyReLU object at 0x112db25b0>] convolutional
[ 1.0453302  -0.00259408  0.12642965  0.6303355   0.10410482  0.4612069
  0.68075335  0.1433216  -0.0479341  -0.05932709 -0.02693686  1.3715192
  5.8151393 ]
Outputs from 79 [<Conv2d Layer with in_channels 1024, out_channels 512, weights with shape (512, 1024, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112db2b50>, <tinygrad.nn.LeakyReLU object at 0x112db2be0>] convolutional
[ 0.27867895 -0.01411781  0.37249184  0.3249805   0.07464156 -0.01514341
 -0.08326214 -0.11692717 -0.07335874 -0.00681355 -0.02763627 -0.00430343
 -0.4868408 ]
Outputs from 80 [<Conv2d Layer with in_channels 512, out_channels 1024, weights with shape (1024, 512, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x112db31c0>, <tinygrad.nn.LeakyReLU object at 0x112db3250>] convolutional
[-0.01786771 -0.09820022 -0.20878397 -0.24386397 -0.18624243 -0.22160463
 -0.07960273 -0.03743645  0.05864856 -0.23411874 -0.12730987 -0.05000082
  0.83901274]
Outputs from 81 [<Conv2d Layer with in_channels 1024, out_channels 255, weights with shape (255, 1024, 1, 1)>] convolutional
[-1.0101236   1.1819768   0.29871386  1.0350411  -0.21650082  0.33548003
 -0.12125522 -0.67977387 -0.89187956 -0.6715983   0.9113428  -1.449262
 -1.3070116 ]
[(116, 90), (156, 198), (373, 326)] 416 80
yolo result (1, 507, 85)
[-1.0101236   1.1819768   0.29871386  1.0350411  -0.21650082  0.33548003
 -0.12125522 -0.67977387 -0.89187956 -0.6715983 ]
Outputs from 82 [<tinygrad.nn.DetectionLayer object at 0x112db3940>] yolo
-1.0101236
Outputs from 83 [<tinygrad.nn.EmptyLayer object at 0x112db39d0>] route
[ 0.27867895 -0.01411781  0.37249184  0.3249805   0.07464156 -0.01514341
 -0.08326214 -0.11692717 -0.07335874 -0.00681355 -0.02763627 -0.00430343
 -0.4868408 ]
Outputs from 84 [<Conv2d Layer with in_channels 512, out_channels 256, weights with shape (256, 512, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x112db3a30>, <tinygrad.nn.LeakyReLU object at 0x112db3ac0>] convolutional
[-0.05657791 -0.08642583  1.2109886  -0.01925558 -0.13523364 -0.11419141
 -0.07595312  0.23183516  0.7160748   0.8384533  -0.08040401 -0.42462468
 -0.4004893 ]
Outputs from 85 [<tinygrad.nn.Upsample object at 0x125bce070>] upsample
[-0.05657791 -0.05657791 -0.08642583 -0.08642583  1.2109886   1.2109886
 -0.01925558 -0.01925558 -0.13523364 -0.13523364 -0.11419141 -0.11419141
 -0.07595312 -0.07595312  0.23183516  0.23183516  0.7160748   0.7160748
  0.8384533   0.8384533  -0.08040401 -0.08040401 -0.42462468 -0.42462468
 -0.4004893  -0.4004893 ]
Outputs from 86 [<tinygrad.nn.EmptyLayer object at 0x125bce0d0>] route
[-0.05657791 -0.05657791 -0.08642583 -0.08642583  1.2109886   1.2109886
 -0.01925558 -0.01925558 -0.13523364 -0.13523364 -0.11419141 -0.11419141
 -0.07595312 -0.07595312  0.23183516  0.23183516  0.7160748   0.7160748
  0.8384533   0.8384533  -0.08040401 -0.08040401 -0.42462468 -0.42462468
 -0.4004893  -0.4004893 ]
Outputs from 87 [<Conv2d Layer with in_channels 768, out_channels 256, weights with shape (256, 768, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x125bce130>, <tinygrad.nn.LeakyReLU object at 0x125bce1c0>] convolutional
[-0.05459297  0.10864335  0.8196174   1.5783279   1.3734344   1.4394646
  0.5699804   1.1607249   1.7440182   1.668271    1.308695    1.5796132
  1.4075538   1.4911944   0.08379024 -0.00398409  0.18519187  0.47918513
 -0.04648548 -0.05139029  3.89734     4.2846336   1.2314798   1.646498
  1.5711298   1.3681613 ]
Outputs from 88 [<Conv2d Layer with in_channels 256, out_channels 512, weights with shape (512, 256, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x125bce760>, <tinygrad.nn.LeakyReLU object at 0x125bce7f0>] convolutional
[-0.02131764  0.348336   -0.032818   -0.11103679 -0.07986082 -0.0816846
 -0.09642933 -0.1588615  -0.16189343 -0.10999488 -0.0939438  -0.15097266
 -0.11238909 -0.10622805 -0.10078511 -0.12415755 -0.05426767 -0.02089836
 -0.05308285 -0.0394934  -0.04018363 -0.06699259 -0.16623598 -0.18065608
 -0.0642347   2.597218  ]
Outputs from 89 [<Conv2d Layer with in_channels 512, out_channels 256, weights with shape (256, 512, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x125bced90>, <tinygrad.nn.LeakyReLU object at 0x125bcee20>] convolutional
[-0.14578909 -0.04084908 -0.06895405 -0.04100375 -0.00885229  0.20448172
  0.05677103 -0.08103484 -0.10037287 -0.10217985 -0.10411687 -0.09614784
 -0.05167472 -0.05479058 -0.02607096 -0.08010504 -0.05870641 -0.05668919
 -0.05477519 -0.14340441 -0.18387452 -0.08054114  1.0029842  -0.00485848
 -0.18391174 -0.21660574]
Outputs from 90 [<Conv2d Layer with in_channels 256, out_channels 512, weights with shape (512, 256, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x125bd0400>, <tinygrad.nn.LeakyReLU object at 0x125bd0490>] convolutional
[-0.0111054   0.00159375  0.58423436  0.83364916  1.0374963   1.134098
  0.9378513   0.85275674  0.63206697  0.82161725  0.53433645  0.64368916
  0.6740689   0.81858027  0.74687994  0.6015973   0.75487876  0.6905823
  0.75374174  1.1314801   1.5451056   0.9777645   1.7960315   0.9677011
 -0.39438748 -0.47175646]
Outputs from 91 [<Conv2d Layer with in_channels 512, out_channels 256, weights with shape (256, 512, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x125bd0a30>, <tinygrad.nn.LeakyReLU object at 0x125bd0ac0>] convolutional
[ 1.2948978  -0.0075087   0.5301415   0.16360605 -0.02175641 -0.02793797
  0.07199293  1.0424559   1.7037367   1.7261945   1.8705665   1.9197099
  1.8694137   1.8144648   1.4953226   1.2829444   1.1878967   1.1158412
  0.6947214   0.4886524  -0.054735   -0.2408384  -0.8257003  -1.1987729
 -0.64368105 -0.17524946]
Outputs from 92 [<Conv2d Layer with in_channels 256, out_channels 512, weights with shape (512, 256, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x125bd20a0>, <tinygrad.nn.LeakyReLU object at 0x125bd2130>] convolutional
[-0.01461433 -0.01170991 -0.02698972  0.13656746  0.21864945  0.36689723
  0.15819941 -0.0040823  -0.00223759 -0.02433867 -0.04251481 -0.00487826
  0.39354932  0.56833804  0.61975265  0.77890146  1.0886669   0.6170285
  0.88394105  0.8621687   0.60277706  0.17217524  0.87563604  3.7188008
  0.79941946 -0.17927626]
Outputs from 93 [<Conv2d Layer with in_channels 512, out_channels 255, weights with shape (255, 512, 1, 1)>] convolutional
[-0.53180254  0.5381544  -0.46923497 -0.08535233 -0.11764678  0.13931692
  0.27474946  0.02494189  0.108573    0.01877806 -0.06585309  0.00075586
  0.1263135   0.1028814   0.23502311  0.4743293  -0.05711065  0.07267494
 -0.15588291 -0.1581001  -0.56175214  0.2842559  -0.02552572  2.303909
 -1.8642462  -1.066957  ]
[(30, 61), (62, 45), (59, 119)] 416 80
yolo result (1, 2028, 85)
[-0.53180254  0.5381544  -0.46923497 -0.08535233 -0.11764678  0.13931692
  0.27474946  0.02494189  0.108573    0.01877806]
Outputs from 94 [<tinygrad.nn.DetectionLayer object at 0x125bd2820>] yolo
-0.53180254
Outputs from 95 [<tinygrad.nn.EmptyLayer object at 0x125bd28b0>] route
[ 1.2948978  -0.0075087   0.5301415   0.16360605 -0.02175641 -0.02793797
  0.07199293  1.0424559   1.7037367   1.7261945   1.8705665   1.9197099
  1.8694137   1.8144648   1.4953226   1.2829444   1.1878967   1.1158412
  0.6947214   0.4886524  -0.054735   -0.2408384  -0.8257003  -1.1987729
 -0.64368105 -0.17524946]
Outputs from 96 [<Conv2d Layer with in_channels 256, out_channels 128, weights with shape (128, 256, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x125bd2910>, <tinygrad.nn.LeakyReLU object at 0x125bd29a0>] convolutional
[-0.02194547  1.329627   -0.23205319 -0.16774121 -0.05209611 -0.09192976
 -0.11445983 -0.23082805 -0.2747088  -0.22101478 -0.19489138 -0.1779365
 -0.13651113 -0.0841293  -0.01637833  0.17796561 -0.03408309  0.2752754
  1.1177442   1.6092      0.00026354 -0.42091352  1.1642992  15.938712
  4.4920664   0.83269536]
Outputs from 97 [<tinygrad.nn.Upsample object at 0x125bd2f10>] upsample
[-0.02194547 -0.02194547  1.329627    1.329627   -0.23205319 -0.23205319
 -0.16774121 -0.16774121 -0.05209611 -0.05209611 -0.09192976 -0.09192976
 -0.11445983 -0.11445983 -0.23082805 -0.23082805 -0.2747088  -0.2747088
 -0.22101478 -0.22101478 -0.19489138 -0.19489138 -0.1779365  -0.1779365
 -0.13651113 -0.13651113 -0.0841293  -0.0841293  -0.01637833 -0.01637833
  0.17796561  0.17796561 -0.03408309 -0.03408309  0.2752754   0.2752754
  1.1177442   1.1177442   1.6092      1.6092      0.00026354  0.00026354
 -0.42091352 -0.42091352  1.1642992   1.1642992  15.938712   15.938712
  4.4920664   4.4920664   0.83269536  0.83269536]
Outputs from 98 [<tinygrad.nn.EmptyLayer object at 0x125bd2f70>] route
[-0.02194547 -0.02194547  1.329627    1.329627   -0.23205319 -0.23205319
 -0.16774121 -0.16774121 -0.05209611 -0.05209611 -0.09192976 -0.09192976
 -0.11445983 -0.11445983 -0.23082805 -0.23082805 -0.2747088  -0.2747088
 -0.22101478 -0.22101478 -0.19489138 -0.19489138 -0.1779365  -0.1779365
 -0.13651113 -0.13651113 -0.0841293  -0.0841293  -0.01637833 -0.01637833
  0.17796561  0.17796561 -0.03408309 -0.03408309  0.2752754   0.2752754
  1.1177442   1.1177442   1.6092      1.6092      0.00026354  0.00026354
 -0.42091352 -0.42091352  1.1642992   1.1642992  15.938712   15.938712
  4.4920664   4.4920664   0.83269536  0.83269536]
Outputs from 99 [<Conv2d Layer with in_channels 384, out_channels 128, weights with shape (128, 384, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x125bd2fd0>, <tinygrad.nn.LeakyReLU object at 0x125bd50a0>] convolutional
[ 3.0470765   2.0540335   0.35944763  0.06564916  0.8588935   0.87892467
 -0.00087393  0.73618186 -0.08984622 -0.01780521 -0.05902132 -0.07933234
 -0.01959973 -0.03078255  0.13865335  0.14929739  1.3371992   1.0854251
 -0.05078095  0.1323521   0.05300375  0.30087474  0.04275997 -0.01272146
  0.27151528  0.89844763 -0.01436837 -0.0130376  -0.0121401  -0.03739536
 -0.03597367 -0.0628259   0.23960644 -0.06785838 -0.04461903 -0.01922441
 -0.04343635 -0.04274875 -0.01017369 -0.02802755 -0.04447917 -0.05711471
 -0.07301804 -0.06852916 -0.44390064 -0.4972613  -0.46150643 -0.48121205
 -0.39115724 -0.37649506 -0.52869266 -0.46135876]
Outputs from 100 [<Conv2d Layer with in_channels 128, out_channels 256, weights with shape (256, 128, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x125bd5640>, <tinygrad.nn.LeakyReLU object at 0x125bd56d0>] convolutional
[ 0.15728107  1.2168858   0.65098464  1.4684122   0.2776784  -0.0449947
 -0.03147323 -0.06367841 -0.02616731 -0.03158673 -0.04084356 -0.06221645
 -0.06192714 -0.00970753 -0.05592237 -0.06699441 -0.06060155 -0.0440248
 -0.01170299 -0.04865121 -0.06936776 -0.11213166 -0.05785563 -0.05767067
 -0.02783173 -0.03992291 -0.04280534 -0.05504316 -0.07885032 -0.09910259
 -0.1480892  -0.13201252 -0.11709424 -0.06670994 -0.07713264 -0.08897849
 -0.11230753 -0.09892358 -0.13132986 -0.10445274 -0.07219867 -0.03492707
 -0.05978486  0.32793167  1.1705364   0.9343382   2.9139411   3.4963727
  2.2496264   1.1455302   2.4644268   3.8158655 ]
Outputs from 101 [<Conv2d Layer with in_channels 256, out_channels 128, weights with shape (128, 256, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x125bd5c70>, <tinygrad.nn.LeakyReLU object at 0x125bd5d00>] convolutional
[ 0.09740294 -0.05850517  0.62712705 -0.01221354  0.7270863   0.64476585
  1.0648059   0.66834223  0.727746    0.924314    1.2859964   0.79304886
  0.44123402  0.00300687  0.04187173  0.24583331  0.7459425   0.935843
  0.78538835  1.0946583   1.2162075   1.3508713   1.0031309   1.1141714
  1.6030108   1.78655     1.1109642   0.96242666  1.0496944   1.4087698
  1.4563749   1.2725577   0.84302473  0.52385724  0.5868891   1.0199418
  0.7736627   0.8413037   1.4284525   1.3167739   1.607825    1.5564176
  1.478075    0.6897541  -0.05179937 -0.10927004  1.4214396   5.2579513
  5.2595315   3.0447354  -0.33681786 -0.1823308 ]
Outputs from 102 [<Conv2d Layer with in_channels 128, out_channels 256, weights with shape (256, 128, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x125bd62e0>, <tinygrad.nn.LeakyReLU object at 0x125bd6370>] convolutional
[-0.20799871 -0.24079648 -0.20990823 -0.14853114 -0.12603574 -0.05753852
  0.06419033 -0.02198894 -0.02647184 -0.04981889 -0.08755324 -0.07934523
 -0.1187095  -0.15093552 -0.1705155  -0.14833304 -0.11507652 -0.15181503
 -0.1639217  -0.18053254 -0.17035307 -0.18979527 -0.18283848 -0.16365659
 -0.10318134 -0.12864524 -0.10416234 -0.12239575 -0.08392704 -0.05628179
 -0.01524993 -0.05437956 -0.07322921 -0.06317338 -0.08253699 -0.07232269
 -0.04947686 -0.06766798 -0.03427472 -0.06385728 -0.08290934 -0.06488875
 -0.09688748 -0.13523309 -0.00639121  0.5266417   0.21884921 -0.15959884
  0.5847324   1.1390867  -0.03447619 -0.0119307 ]
Outputs from 103 [<Conv2d Layer with in_channels 256, out_channels 128, weights with shape (128, 256, 1, 1)>, <tinygrad.nn.BatchNorm2D object at 0x125bd6910>, <tinygrad.nn.LeakyReLU object at 0x125bd69a0>] convolutional
[ 0.42035133  2.4910092   0.7006779   1.3147337   2.2424293   1.9257987
  1.530512    1.6724492   1.6823535   2.0895364   1.7523257   1.9507778
  1.9533236   2.1014585   2.2903767   2.1958613   2.4350896   1.8947197
  2.3890855   2.405123    2.3409865   2.3239448   2.3164558   2.220044
  2.1462698   1.5167891   1.6577187   2.291457    1.8231554   1.7585818
  1.5259218   1.3238363   0.8164378   1.5054133   1.166062    1.1080118
  0.81697786  1.0178627   0.98395056  1.6659366   2.5690682   2.7450984
  2.8761933   2.754394    2.9276562   1.6457603  -0.08580095 -0.10101128
 -0.02506621 -0.3467855  -0.26715958 -0.3920277 ]
Outputs from 104 [<Conv2d Layer with in_channels 128, out_channels 256, weights with shape (256, 128, 3, 3)>, <tinygrad.nn.BatchNorm2D object at 0x125bd6f40>, <tinygrad.nn.LeakyReLU object at 0x125bd6fd0>] convolutional
[ 0.20412542 -0.01403945  0.12307705 -0.07986283 -0.10756812 -0.09236478
 -0.12067217 -0.12658516 -0.19020116 -0.22387233 -0.23622575 -0.20660801
 -0.14171275 -0.09802785 -0.07274791 -0.07856897 -0.08286858 -0.12221728
 -0.13194658 -0.1448203  -0.1353559  -0.11390585 -0.11557772 -0.11866756
 -0.13550174 -0.13981763 -0.09021062 -0.10982305 -0.08570363 -0.06874486
 -0.05695735 -0.09839115 -0.0749464  -0.06908312 -0.06044945 -0.03648223
 -0.04444428 -0.07927996 -0.09855906 -0.13137132 -0.21673702 -0.36060104
 -0.56921345 -0.72339696 -0.746691   -0.7006192  -0.7278692  -0.56601286
 -0.3423273  -0.28832635 -0.22325347 -0.22333391]
Outputs from 105 [<Conv2d Layer with in_channels 256, out_channels 255, weights with shape (255, 256, 1, 1)>] convolutional
[ 0.10120834 -0.26901928  0.7248664   0.3489787  -0.03630926  0.04623816
  0.05874362 -0.20213577 -0.08755029  0.14954878 -0.12045843  0.10938261
 -0.0651966   0.01964001  0.19605759  0.27842924  0.05980372 -0.05652129
  0.14153384  0.07431389  0.04863232  0.0666716   0.05358431  0.21380666
  0.11996695 -0.17293599  0.24650833  0.25177187 -0.07698864  0.26539043
  0.17927739  0.03510409 -0.35723922  0.02743911 -0.08008226  0.25638363
  0.08459255  0.37042728  0.06520694  0.08365669 -0.01073716  0.17257902
  0.12807098  0.16297916 -0.16356021 -0.20044556  0.02717112  0.6680978
  0.02175542  0.19597131  0.12103269  0.43955025]
[(10, 13), (16, 30), (33, 23)] 416 80
yolo result (1, 8112, 85)
[ 0.10120834 -0.26901928  0.7248664   0.3489787  -0.03630926  0.04623816
  0.05874362 -0.20213577 -0.08755029  0.14954878]
Outputs from 106 [<tinygrad.nn.DetectionLayer object at 0x125bd9700>] yolo
0.10120834
did inference in 8.21 s
Prediction result:
(1, 10647, 85)
[ 0.33548003 -0.12125522 -0.67977387 -0.89187956 -0.6715983 ]
Prediction should be:
tensor([0.37478, 0.00032929, 0.072857, 0.00036275, 0.0012436])
non zero ind
(1862,)
Image_pred_
(1862, 7)
Classes
(80,)
Shapes:
(1862, 7)
(1862,)
